{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsmcel/Castillos-/blob/main/train_embeddings_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de Modelo para Clasificaci√≥n de Trenes\n",
        "# ===================================================\n",
        "# Este notebook entrena un modelo para clasificar im√°genes de trenes\n",
        "# y resolver el problema de falsos positivos\n",
        "\n",
        "# PARTE 1: INSTALACI√ìN DE DEPENDENCIAS\n",
        "# ====================================\n",
        "# Primero instalamos todas las bibliotecas necesarias\n",
        "!pip install torch torchvision onnx onnxruntime\n",
        "\n",
        "# Importamos las bibliotecas necesarias\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, models, transforms\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "# Verificamos que todo se haya instalado correctamente\n",
        "print(\"‚úÖ Todas las bibliotecas instaladas correctamente\")\n",
        "\n",
        "# PARTE 2: CONFIGURACI√ìN INICIAL\n",
        "# =============================\n",
        "# Definimos las variables de configuraci√≥n\n",
        "class Config:\n",
        "    # Rutas (ajusta estas rutas seg√∫n donde subas tus im√°genes)\n",
        "    DATA_DIR = \"/content/train_images\"\n",
        "    TEST_DIR = \"/content/test_images\"\n",
        "    OUTPUT_DIR = \"/content/output\"\n",
        "\n",
        "    # Clases iniciales para el enfoque incremental\n",
        "    SELECTED_CLASSES = [\"talgo\", \"tardienta\", \"ter\"]\n",
        "\n",
        "    # Par√°metros de entrenamiento\n",
        "    BATCH_SIZE = 16\n",
        "    NUM_EPOCHS = 10\n",
        "    LEARNING_RATE = 0.001\n",
        "    IMG_SIZE = 224\n",
        "\n",
        "    # Par√°metros del modelo\n",
        "    MODEL_NAME = \"efficientnet_b0\"\n",
        "\n",
        "# Creamos una instancia de la configuraci√≥n\n",
        "config = Config()\n",
        "\n",
        "# Creamos las carpetas de salida si no existen\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"models\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"embeddings\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"visualizations\"), exist_ok=True)\n",
        "\n",
        "# Configuramos el dispositivo (GPU o CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilizando dispositivo: {device}\")\n",
        "print(f\"üîç Si ves 'cuda', est√°s usando una GPU. Si ves 'cpu', est√°s usando la CPU.\")\n",
        "\n",
        "# PARTE 3: DIAGN√ìSTICO DEL ENTORNO Y DATASET\n",
        "# =========================================\n",
        "# Verificamos que todo est√© configurado correctamente\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîç DIAGN√ìSTICO COMPLETO DEL ENTORNO Y DATASET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Verificar configuraci√≥n\n",
        "print(\"\\nüìã CONFIGURACI√ìN ACTUAL:\")\n",
        "print(f\"DATA_DIR = '{config.DATA_DIR}'\")\n",
        "print(f\"TEST_DIR = '{config.TEST_DIR}'\")\n",
        "print(f\"OUTPUT_DIR = '{config.OUTPUT_DIR}'\")\n",
        "print(f\"SELECTED_CLASSES = {config.SELECTED_CLASSES}\")\n",
        "print(f\"BATCH_SIZE = {config.BATCH_SIZE}\")\n",
        "print(f\"NUM_EPOCHS = {config.NUM_EPOCHS}\")\n",
        "print(f\"LEARNING_RATE = {config.LEARNING_RATE}\")\n",
        "\n",
        "# Verificar existencia de directorios\n",
        "print(\"\\nüìÅ VERIFICACI√ìN DE DIRECTORIOS:\")\n",
        "print(f\"¬øExiste DATA_DIR? {'‚úÖ S√ç' if os.path.exists(config.DATA_DIR) else '‚ùå NO'}\")\n",
        "print(f\"¬øExiste TEST_DIR? {'‚úÖ S√ç' if os.path.exists(config.TEST_DIR) else '‚ùå NO'}\")\n",
        "print(f\"¬øExiste OUTPUT_DIR? {'‚úÖ S√ç' if os.path.exists(config.OUTPUT_DIR) else '‚ùå NO'}\")\n",
        "\n",
        "# Verificar contenido de directorios de entrenamiento\n",
        "print(\"\\nüìÇ CONTENIDO DE DIRECTORIOS DE ENTRENAMIENTO:\")\n",
        "if os.path.exists(config.DATA_DIR):\n",
        "    all_dirs = os.listdir(config.DATA_DIR)\n",
        "    print(f\"Carpetas en DATA_DIR: {all_dirs}\")\n",
        "\n",
        "    for class_name in config.SELECTED_CLASSES:\n",
        "        class_path = os.path.join(config.DATA_DIR, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            files = os.listdir(class_path)\n",
        "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            print(f\"\\nClase '{class_name}':\")\n",
        "            print(f\"  - Ruta: {class_path}\")\n",
        "            print(f\"  - Total archivos: {len(files)}\")\n",
        "            print(f\"  - Archivos de imagen: {len(image_files)}\")\n",
        "\n",
        "            # Intentar abrir una imagen para verificar que sea v√°lida\n",
        "            if image_files:\n",
        "                try:\n",
        "                    img_path = os.path.join(class_path, image_files[0])\n",
        "                    img = Image.open(img_path)\n",
        "                    print(f\"  - Prueba de imagen: ‚úÖ Imagen v√°lida ({img.size[0]}x{img.size[1]})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  - Prueba de imagen: ‚ùå Error al abrir imagen: {e}\")\n",
        "            else:\n",
        "                print(f\"  - ‚ö†Ô∏è No hay archivos de imagen en esta carpeta\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå La carpeta para la clase '{class_name}' no existe en {config.DATA_DIR}\")\n",
        "\n",
        "# Verificar contenido de directorios de prueba\n",
        "print(\"\\nüìÇ CONTENIDO DE DIRECTORIOS DE PRUEBA:\")\n",
        "if os.path.exists(config.TEST_DIR):\n",
        "    all_dirs = os.listdir(config.TEST_DIR)\n",
        "    print(f\"Carpetas en TEST_DIR: {all_dirs}\")\n",
        "\n",
        "    for class_name in config.SELECTED_CLASSES + [\"otros\"]:\n",
        "        class_path = os.path.join(config.TEST_DIR, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            files = os.listdir(class_path)\n",
        "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            print(f\"\\nClase de prueba '{class_name}':\")\n",
        "            print(f\"  - Ruta: {class_path}\")\n",
        "            print(f\"  - Total archivos: {len(files)}\")\n",
        "            print(f\"  - Archivos de imagen: {len(image_files)}\")\n",
        "\n",
        "            # Intentar abrir una imagen para verificar que sea v√°lida\n",
        "            if image_files:\n",
        "                try:\n",
        "                    img_path = os.path.join(class_path, image_files[0])\n",
        "                    img = Image.open(img_path)\n",
        "                    print(f\"  - Prueba de imagen: ‚úÖ Imagen v√°lida ({img.size[0]}x{img.size[1]})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  - Prueba de imagen: ‚ùå Error al abrir imagen: {e}\")\n",
        "            else:\n",
        "                print(f\"  - ‚ö†Ô∏è No hay archivos de imagen en esta carpeta\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå La carpeta para la clase '{class_name}' no existe en {config.TEST_DIR}\")\n",
        "\n",
        "print(\"\\n‚úÖ DIAGN√ìSTICO COMPLETADO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# PARTE 4: PREPARACI√ìN DE DATOS\n",
        "# ============================\n",
        "# Definimos las transformaciones para las im√°genes\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),  # Redimensionar todas las im√°genes al mismo tama√±o\n",
        "    transforms.RandomHorizontalFlip(p=0.5),                 # Voltear horizontalmente con 50% de probabilidad\n",
        "    transforms.RandomRotation(degrees=10),                  # Rotar ligeramente\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variar colores\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),     # Peque√±as deformaciones\n",
        "    transforms.ToTensor(),                                  # Convertir a tensor (formato que usa PyTorch)\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],        # Normalizar valores de p√≠xeles\n",
        "                         std=[0.229, 0.224, 0.225])         # (estos son valores est√°ndar para im√°genes)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),  # Redimensionar\n",
        "    transforms.ToTensor(),                                  # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],        # Normalizar\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Funci√≥n para cargar el dataset desde carpetas\n",
        "def load_dataset(data_dir, transform=None, selected_classes=None):\n",
        "    \"\"\"\n",
        "    Carga un dataset de im√°genes organizadas en carpetas por clase.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directorio con las im√°genes organizadas en subcarpetas por clase\n",
        "        transform: Transformaciones a aplicar a las im√°genes\n",
        "        selected_classes: Lista de clases espec√≠ficas a incluir (None = todas)\n",
        "\n",
        "    Returns:\n",
        "        dataset: Dataset cargado\n",
        "        class_names: Nombres de las clases\n",
        "    \"\"\"\n",
        "    print(f\"Cargando dataset desde: {data_dir}\")\n",
        "    print(f\"Clases seleccionadas: {selected_classes}\")\n",
        "\n",
        "    try:\n",
        "        # Si tenemos clases seleccionadas, filtramos solo esas carpetas\n",
        "        if selected_classes:\n",
        "            # Verificar qu√© clases est√°n disponibles en el directorio\n",
        "            available_classes = [d for d in os.listdir(data_dir)\n",
        "                               if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "            print(f\"Clases disponibles en {data_dir}: {available_classes}\")\n",
        "\n",
        "            # Filtrar solo las clases seleccionadas que est√°n disponibles\n",
        "            valid_classes = [c for c in selected_classes if c in available_classes]\n",
        "\n",
        "            if not valid_classes:\n",
        "                print(f\"‚ö†Ô∏è Ninguna de las clases seleccionadas {selected_classes} est√° disponible en {data_dir}\")\n",
        "                print(f\"‚ö†Ô∏è Usando todas las clases disponibles\")\n",
        "                dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "                class_names = dataset.classes\n",
        "            else:\n",
        "                print(f\"üîç Filtrando solo las clases: {valid_classes}\")\n",
        "\n",
        "                # Crear un dataset personalizado con solo las clases seleccionadas\n",
        "                # Primero cargamos todo el dataset para obtener la estructura\n",
        "                full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "                print(f\"Dataset completo cargado con clases: {full_dataset.classes}\")\n",
        "                print(f\"Mapeo de clases a √≠ndices: {full_dataset.class_to_idx}\")\n",
        "\n",
        "                # Luego filtramos solo las clases que nos interesan\n",
        "                selected_indices = [i for i, (_, label) in enumerate(full_dataset.samples)\n",
        "                                  if full_dataset.classes[label] in valid_classes]\n",
        "\n",
        "                print(f\"√çndices seleccionados: {len(selected_indices)} de {len(full_dataset)}\")\n",
        "\n",
        "                # Creamos un subconjunto con solo esas clases\n",
        "                dataset = Subset(full_dataset, selected_indices)\n",
        "                class_names = valid_classes\n",
        "\n",
        "                print(f\"‚úÖ Dataset filtrado creado con {len(dataset)} im√°genes\")\n",
        "                return dataset, class_names\n",
        "        else:\n",
        "            # Si no hay filtro, cargamos todas las clases\n",
        "            dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "            class_names = dataset.classes\n",
        "\n",
        "        print(f\"‚úÖ Dataset cargado con {len(dataset)} im√°genes y {len(class_names)} clases\")\n",
        "        print(f\"üè∑Ô∏è Clases: {class_names}\")\n",
        "        return dataset, class_names\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el dataset: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "# Funci√≥n para dividir el dataset en entrenamiento y validaci√≥n\n",
        "def split_dataset(dataset, val_split=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    Divide un dataset en conjuntos de entrenamiento y validaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset completo\n",
        "        val_split: Proporci√≥n para validaci√≥n (0.2 = 20%)\n",
        "        seed: Semilla aleatoria para reproducibilidad\n",
        "\n",
        "    Returns:\n",
        "        train_dataset: Conjunto de entrenamiento\n",
        "        val_dataset: Conjunto de validaci√≥n\n",
        "    \"\"\"\n",
        "    print(f\"Dividiendo dataset en entrenamiento ({1-val_split:.0%}) y validaci√≥n ({val_split:.0%})\")\n",
        "\n",
        "    try:\n",
        "        # Obtener √≠ndices de todas las muestras\n",
        "        dataset_size = len(dataset)\n",
        "        indices = list(range(dataset_size))\n",
        "\n",
        "        # Dividir √≠ndices en entrenamiento y validaci√≥n\n",
        "        val_size = int(val_split * dataset_size)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(indices)\n",
        "        train_indices, val_indices = indices[val_size:], indices[:val_size]\n",
        "\n",
        "        print(f\"Dataset original: {dataset_size} im√°genes\")\n",
        "        print(f\"√çndices de entrenamiento: {len(train_indices)} im√°genes\")\n",
        "        print(f\"√çndices de validaci√≥n: {len(val_indices)} im√°genes\")\n",
        "\n",
        "        # Crear subconjuntos\n",
        "        train_dataset = Subset(dataset, train_indices)\n",
        "        val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "        print(f\"‚úÖ Dataset dividido: {len(train_dataset)} im√°genes para entrenamiento, {len(val_dataset)} im√°genes para validaci√≥n\")\n",
        "        return train_dataset, val_dataset\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al dividir el dataset: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "# Funci√≥n para crear dataloaders (cargadores de datos para el entrenamiento)\n",
        "def create_dataloaders(train_dataset, val_dataset, batch_size=32, num_workers=2):\n",
        "    \"\"\"\n",
        "    Crea dataloaders para entrenamiento y validaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Conjunto de entrenamiento\n",
        "        val_dataset: Conjunto de validaci√≥n\n",
        "        batch_size: Tama√±o del lote (cu√°ntas im√°genes procesar a la vez)\n",
        "        num_workers: N√∫mero de hilos para cargar datos (ajustar seg√∫n CPU)\n",
        "\n",
        "    Returns:\n",
        "        train_loader: Dataloader para entrenamiento\n",
        "        val_loader: Dataloader para validaci√≥n\n",
        "    \"\"\"\n",
        "    print(f\"Creando dataloaders con batch_size={batch_size}, num_workers={num_workers}\")\n",
        "\n",
        "    try:\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,              # Mezclar datos en cada √©poca\n",
        "            num_workers=num_workers,   # Hilos para cargar datos\n",
        "            pin_memory=True            # Mejora rendimiento con GPU\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,             # No es necesario mezclar datos de validaci√≥n\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Dataloaders creados:\")\n",
        "        print(f\"   Train loader: {len(train_loader)} lotes\")\n",
        "        print(f\"   Val loader: {len(val_loader)} lotes\")\n",
        "\n",
        "        return train_loader, val_loader\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al crear dataloaders: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "# PARTE 5: CARGA Y PREPARACI√ìN DEL MODELO\n",
        "# ======================================\n",
        "# Funci√≥n para cargar el modelo preentrenado\n",
        "def load_model(model_name, num_classes):\n",
        "    \"\"\"\n",
        "    Carga un modelo preentrenado y lo adapta para nuestro problema.\n",
        "\n",
        "    Args:\n",
        "        model_name: Nombre del modelo a cargar\n",
        "        num_classes: N√∫mero de clases para la capa final\n",
        "\n",
        "    Returns:\n",
        "        model: Modelo adaptado\n",
        "    \"\"\"\n",
        "    print(f\"Cargando modelo {model_name} para {num_classes} clases\")\n",
        "\n",
        "    try:\n",
        "        if model_name == \"efficientnet_b0\":\n",
        "            # Cargar EfficientNet preentrenado\n",
        "            model = models.efficientnet_b0(weights='DEFAULT')\n",
        "\n",
        "            # Modificar la capa final para nuestro n√∫mero de clases\n",
        "            in_features = model.classifier[1].in_features\n",
        "            model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        elif model_name == \"resnet50\":\n",
        "            # Cargar ResNet50 preentrenado\n",
        "            model = models.resnet50(weights='DEFAULT')\n",
        "\n",
        "            # Modificar la capa final para nuestro n√∫mero de clases\n",
        "            in_features = model.fc.in_features\n",
        "            model.fc = nn.Linear(in_features, num_classes)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Modelo {model_name} no soportado\")\n",
        "\n",
        "        # Mover modelo a GPU si est√° disponible\n",
        "        model = model.to(device)\n",
        "\n",
        "        print(f\"‚úÖ Modelo {model_name} cargado y adaptado para {num_classes} clases\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el modelo: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# PARTE 6: ENTRENAMIENTO DEL MODELO\n",
        "# ================================\n",
        "# Funci√≥n para entrenar el modelo\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Entrena el modelo y muestra el progreso detallado.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üöÇ INICIANDO ENTRENAMIENTO DEL MODELO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Verificar que los dataloaders tengan datos\n",
        "    print(f\"\\nüìä VERIFICACI√ìN DE DATALOADERS:\")\n",
        "    print(f\"Train loader: {len(train_loader)} lotes (batch_size={config.BATCH_SIZE})\")\n",
        "    print(f\"Val loader: {len(val_loader)} lotes (batch_size={config.BATCH_SIZE})\")\n",
        "\n",
        "    if len(train_loader) == 0:\n",
        "        print(\"‚ùå ERROR: El dataloader de entrenamiento est√° vac√≠o. No hay im√°genes para entrenar.\")\n",
        "        return model\n",
        "\n",
        "    # Verificar una muestra del dataloader\n",
        "    print(\"\\nüîç VERIFICANDO MUESTRA DE DATOS:\")\n",
        "    try:\n",
        "        sample_batch, sample_labels = next(iter(train_loader))\n",
        "        print(f\"Forma del lote de im√°genes: {sample_batch.shape}\")\n",
        "        print(f\"Forma de las etiquetas: {sample_labels.shape}\")\n",
        "        print(f\"Rango de valores de las im√°genes: [{sample_batch.min().item():.4f}, {sample_batch.max().item():.4f}]\")\n",
        "        print(f\"Etiquetas en el lote: {sample_labels.tolist()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERROR al verificar muestra: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # Entrenamiento\n",
        "    best_val_acc = 0.0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n{'='*20} √âpoca {epoch+1}/{num_epochs} {'='*20}\")\n",
        "\n",
        "        # Modo entrenamiento\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        print(f\"‚è≥ Iniciando entrenamiento de √©poca {epoch+1}...\")\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            batch_count += 1\n",
        "            if batch_idx == 0:\n",
        "                print(f\"‚úÖ Primer lote cargado correctamente\")\n",
        "\n",
        "            # Mover datos a GPU si est√° disponible\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Poner gradientes a cero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass y optimizaci√≥n\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Estad√≠sticas\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Mostrar progreso cada 5 lotes\n",
        "            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):\n",
        "                elapsed_time = time.time() - start_time\n",
        "                print(f\"  Lote {batch_idx+1}/{len(train_loader)} | \"\n",
        "                      f\"P√©rdida: {train_loss/(batch_idx+1):.4f} | \"\n",
        "                      f\"Precisi√≥n: {100.*train_correct/train_total:.2f}% | \"\n",
        "                      f\"Tiempo: {elapsed_time:.2f}s\")\n",
        "\n",
        "        # Calcular estad√≠sticas de entrenamiento\n",
        "        train_loss = train_loss / batch_count if batch_count > 0 else 0\n",
        "        train_acc = 100. * train_correct / train_total if train_total > 0 else 0\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Modo evaluaci√≥n\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        print(f\"\\n‚è≥ Iniciando evaluaci√≥n de √©poca {epoch+1}...\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "                batch_count += 1\n",
        "                if batch_idx == 0:\n",
        "                    print(f\"‚úÖ Primer lote de validaci√≥n cargado correctamente\")\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Calcular estad√≠sticas de validaci√≥n\n",
        "        val_loss = val_loss / batch_count if batch_count > 0 else 0\n",
        "        val_acc = 100. * val_correct / val_total if val_total > 0 else 0\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        # Mostrar resultados de la √©poca\n",
        "        print(f\"\\nüìä Resultados de √©poca {epoch+1}:\")\n",
        "        print(f\"  Entrenamiento - P√©rdida: {train_loss:.4f}, Precisi√≥n: {train_acc:.2f}%\")\n",
        "        print(f\"  Validaci√≥n - P√©rdida: {val_loss:.4f}, Precisi√≥n: {val_acc:.2f}%\")\n",
        "\n",
        "        # Guardar el mejor modelo\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            print(f\"  üíæ Guardando mejor modelo (precisi√≥n: {val_acc:.2f}%)\")\n",
        "            torch.save(model.state_dict(), os.path.join(config.OUTPUT_DIR, 'models', 'best_model.pth'))\n",
        "\n",
        "    print(\"\\n‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
        "    print(f\"Mejor precisi√≥n de validaci√≥n: {best_val_acc:.2f}%\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Visualizar curvas de entrenamiento\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Entrenamiento')\n",
        "    plt.plot(val_losses, label='Validaci√≥n')\n",
        "    plt.title('P√©rdida durante el entrenamiento')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('P√©rdida')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accs, label='Entrenamiento')\n",
        "    plt.plot(val_accs, label='Validaci√≥n')\n",
        "    plt.title('Precisi√≥n durante el entrenamiento')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('Precisi√≥n (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, 'visualizations', 'training_curves.png'))\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# PARTE 7: EXTRACCI√ìN DE EMBEDDINGS\n",
        "# ===============================\n",
        "# Funci√≥n para extraer embeddings del modelo entrenado\n",
        "def extract_embeddings(model, dataloader, class_names):\n",
        "    \"\"\"\n",
        "    Extrae embeddings del modelo entrenado para todas las im√°genes.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üîç EXTRAYENDO EMBEDDINGS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Verificar que el dataloader tenga datos\n",
        "    if len(dataloader) == 0:\n",
        "        print(\"‚ùå ERROR: El dataloader est√° vac√≠o. No hay im√°genes para extraer embeddings.\")\n",
        "        return None, None\n",
        "\n",
        "    # Crear un modelo truncado que devuelva los embeddings\n",
        "    if isinstance(model, models.efficientnet.EfficientNet):\n",
        "        # Para EfficientNet, eliminamos la capa de clasificaci√≥n\n",
        "        embedding_model = nn.Sequential(*list(model.children())[:-1])\n",
        "    elif isinstance(model, models.resnet.ResNet):\n",
        "        # Para ResNet, eliminamos la capa fully connected\n",
        "        embedding_model = nn.Sequential(*list(model.children())[:-1])\n",
        "    else:\n",
        "        print(f\"‚ùå Tipo de modelo no soportado para extracci√≥n de embeddings: {type(model)}\")\n",
        "        return None, None\n",
        "\n",
        "    embedding_model = embedding_model.to(device)\n",
        "    embedding_model.eval()\n",
        "\n",
        "    # Extraer embeddings\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"‚è≥ Extrayendo embeddings...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
        "            if batch_idx == 0:\n",
        "                print(f\"‚úÖ Primer lote cargado correctamente\")\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = embedding_model(inputs)\n",
        "\n",
        "            # Aplanar los embeddings\n",
        "            embeddings = outputs.view(outputs.size(0), -1).cpu().numpy()\n",
        "\n",
        "            all_embeddings.append(embeddings)\n",
        "            all_labels.append(labels.numpy())\n",
        "\n",
        "            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(dataloader):\n",
        "                print(f\"  Procesado lote {batch_idx+1}/{len(dataloader)}\")\n",
        "\n",
        "    # Concatenar todos los embeddings y etiquetas\n",
        "    embeddings = np.vstack(all_embeddings)\n",
        "    labels = np.concatenate(all_labels)\n",
        "\n",
        "    print(f\"‚úÖ Embeddings extra√≠dos: {embeddings.shape}\")\n",
        "\n",
        "    # Normalizar embeddings (L2 norm)\n",
        "    from sklearn.preprocessing import normalize\n",
        "    embeddings = normalize(embeddings, axis=1)\n",
        "\n",
        "    # Crear diccionario de embeddings por clase\n",
        "    embeddings_by_class = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        class_name = class_names[label]\n",
        "        if class_name not in embeddings_by_class:\n",
        "            embeddings_by_class[class_name] = []\n",
        "        embeddings_by_class[class_name].append(embeddings[i])\n",
        "\n",
        "    # Calcular embedding promedio por clase\n",
        "    average_embeddings = {}\n",
        "    for class_name, class_embeddings in embeddings_by_class.items():\n",
        "        average_embeddings[class_name] = np.mean(class_embeddings, axis=0)\n",
        "\n",
        "    print(f\"‚úÖ Embeddings promedio calculados para {len(average_embeddings)} clases\")\n",
        "\n",
        "    # Guardar embeddings\n",
        "    import json\n",
        "\n",
        "    # Convertir embeddings a lista para poder serializarlos\n",
        "    embeddings_json = {\n",
        "        \"embeddings\": [emb.tolist() for emb in average_embeddings.values()],\n",
        "        \"label_names\": list(average_embeddings.keys())\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(config.OUTPUT_DIR, 'embeddings', 'dataset_embeddings.json'), 'w') as f:\n",
        "        json.dump(embeddings_json, f)\n",
        "\n",
        "    print(f\"üíæ Embeddings guardados en {os.path.join(config.OUTPUT_DIR, 'embeddings', 'dataset_embeddings.json')}\")\n",
        "\n",
        "    return embeddings, labels\n",
        "\n",
        "# PARTE 8: EXPORTACI√ìN DEL MODELO A ONNX\n",
        "# ====================================\n",
        "# Funci√≥n para exportar el modelo a formato ONNX\n",
        "def export_to_onnx(model, sample_input, output_path):\n",
        "    \"\"\"\n",
        "    Exporta el modelo a formato ONNX para inferencia.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üì¶ EXPORTANDO MODELO A ONNX\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    try:\n",
        "        # Asegurarse de que el modelo est√© en modo evaluaci√≥n\n",
        "        model.eval()\n",
        "\n",
        "        # Preparar entrada de ejemplo\n",
        "        dummy_input = torch.randn(1, 3, config.IMG_SIZE, config.IMG_SIZE, device=device)\n",
        "\n",
        "        # Exportar modelo a ONNX\n",
        "        torch.onnx.export(\n",
        "            model,                      # Modelo a exportar\n",
        "            dummy_input,                # Entrada de ejemplo\n",
        "            output_path,                # Ruta de salida\n",
        "            export_params=True,         # Exportar par√°metros\n",
        "            opset_version=12,           # Versi√≥n de ONNX\n",
        "            do_constant_folding=True,   # Optimizaci√≥n\n",
        "            input_names=['input'],      # Nombre de la entrada\n",
        "            output_names=['output'],    # Nombre de la salida\n",
        "            dynamic_axes={              # Ejes din√°micos (para tama√±os de lote variables)\n",
        "                'input': {0: 'batch_size'},\n",
        "                'output': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Verificar el modelo ONNX\n",
        "        onnx_model = onnx.load(output_path)\n",
        "        onnx.checker.check_model(onnx_model)\n",
        "\n",
        "        print(f\"‚úÖ Modelo exportado a ONNX: {output_path}\")\n",
        "\n",
        "        # Probar inferencia con ONNX Runtime\n",
        "        print(\"üîç Probando inferencia con ONNX Runtime...\")\n",
        "\n",
        "        # Crear sesi√≥n de ONNX Runtime\n",
        "        session = onnxruntime.InferenceSession(output_path)\n",
        "\n",
        "        # Preparar entrada\n",
        "        input_name = session.get_inputs()[0].name\n",
        "        output_name = session.get_outputs()[0].name\n",
        "\n",
        "        # Ejecutar inferencia\n",
        "        dummy_input_numpy = dummy_input.cpu().numpy()\n",
        "        outputs = session.run([output_name], {input_name: dummy_input_numpy})\n",
        "\n",
        "        print(f\"‚úÖ Inferencia con ONNX Runtime exitosa\")\n",
        "        print(f\"   Forma de la salida: {outputs[0].shape}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al exportar modelo a ONNX: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "# PARTE 9: EJECUCI√ìN PRINCIPAL\n",
        "# ==========================\n",
        "# Cargar dataset de entrenamiento\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ INICIANDO PROCESO DE ENTRENAMIENTO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Cargar dataset de entrenamiento\n",
        "train_dataset, class_names = load_dataset(\n",
        "    config.DATA_DIR,\n",
        "    transform=train_transforms,\n",
        "    selected_classes=config.SELECTED_CLASSES\n",
        ")\n",
        "\n",
        "if train_dataset is None or len(train_dataset) == 0:\n",
        "    print(\"‚ùå ERROR: No se pudo cargar el dataset de entrenamiento o est√° vac√≠o.\")\n",
        "else:\n",
        "    # Dividir en entrenamiento y validaci√≥n\n",
        "    train_subset, val_subset = split_dataset(train_dataset, val_split=0.2)\n",
        "\n",
        "    if train_subset is None or val_subset is None:\n",
        "        print(\"‚ùå ERROR: No se pudo dividir el dataset.\")\n",
        "    else:\n",
        "        # Crear dataloaders\n",
        "        train_loader, val_loader = create_dataloaders(\n",
        "            train_subset,\n",
        "            val_subset,\n",
        "            batch_size=config.BATCH_SIZE,\n",
        "            num_workers=2\n",
        "        )\n",
        "\n",
        "        if train_loader is None or val_loader is None:\n",
        "            print(\"‚ùå ERROR: No se pudieron crear los dataloaders.\")\n",
        "        else:\n",
        "            # Cargar modelo\n",
        "            model = load_model(config.MODEL_NAME, len(class_names))\n",
        "\n",
        "            if model is None:\n",
        "                print(\"‚ùå ERROR: No se pudo cargar el modelo.\")\n",
        "            else:\n",
        "                # Definir criterio y optimizador\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "                # Entrenar modelo\n",
        "                trained_model = train_model(\n",
        "                    model,\n",
        "                    train_loader,\n",
        "                    val_loader,\n",
        "                    criterion,\n",
        "                    optimizer,\n",
        "                    num_epochs=config.NUM_EPOCHS\n",
        "                )\n",
        "\n",
        "                # Cargar el mejor modelo guardado\n",
        "                best_model_path = os.path.join(config.OUTPUT_DIR, 'models', 'best_model.pth')\n",
        "                if os.path.exists(best_model_path):\n",
        "                    print(f\"Cargando el mejor modelo desde {best_model_path}\")\n",
        "                    model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "                # Extraer embeddings\n",
        "                test_dataset, test_class_names = load_dataset(\n",
        "                    config.TEST_DIR,\n",
        "                    transform=val_transforms,\n",
        "                    selected_classes=config.SELECTED_CLASSES\n",
        "                )\n",
        "\n",
        "                if test_dataset is not None and len(test_dataset) > 0:\n",
        "                    test_loader = DataLoader(\n",
        "                        test_dataset,\n",
        "                        batch_size=config.BATCH_SIZE,\n",
        "                        shuffle=False,\n",
        "                        num_workers=2,\n",
        "                        pin_memory=True\n",
        "                    )\n",
        "\n",
        "                    # Extraer embeddings\n",
        "                    embeddings, labels = extract_embeddings(model, test_loader, test_class_names)\n",
        "\n",
        "                # Exportar modelo a ONNX\n",
        "                onnx_path = os.path.join(config.OUTPUT_DIR, 'models', 'efficientnet_model.onnx')\n",
        "                export_success = export_to_onnx(model, None, onnx_path)\n",
        "\n",
        "                if export_success:\n",
        "                    print(\"\\n\" + \"=\"*50)\n",
        "                    print(\"‚úÖ PROCESO COMPLETADO EXITOSAMENTE\")\n",
        "                    print(\"=\"*50)\n",
        "                    print(f\"\\nüìÅ Archivos generados:\")\n",
        "                    print(f\"   - Modelo ONNX: {onnx_path}\")\n",
        "                    print(f\"   - Embeddings: {os.path.join(config.OUTPUT_DIR, 'embeddings', 'dataset_embeddings.json')}\")\n",
        "                    print(f\"   - Visualizaciones: {os.path.join(config.OUTPUT_DIR, 'visualizations', 'training_curves.png')}\")\n",
        "                    print(\"\\nüîç Estos archivos son necesarios para usar el script compare_image_onnx.js\")\n",
        "                else:\n",
        "                    print(\"\\n‚ùå ERROR: No se pudo exportar el modelo a ONNX.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nrOi94VlC5zO",
        "outputId": "ee8b5bf6-6f1c-4de7-ed8a-b7ab88fabc73"
      },
      "id": "nrOi94VlC5zO",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas las bibliotecas instaladas correctamente\n",
            "Utilizando dispositivo: cuda\n",
            "üîç Si ves 'cuda', est√°s usando una GPU. Si ves 'cpu', est√°s usando la CPU.\n",
            "\n",
            "==================================================\n",
            "üîç DIAGN√ìSTICO COMPLETO DEL ENTORNO Y DATASET\n",
            "==================================================\n",
            "\n",
            "üìã CONFIGURACI√ìN ACTUAL:\n",
            "DATA_DIR = '/content/train_images'\n",
            "TEST_DIR = '/content/test_images'\n",
            "OUTPUT_DIR = '/content/output'\n",
            "SELECTED_CLASSES = ['talgo', 'tardienta', 'ter']\n",
            "BATCH_SIZE = 16\n",
            "NUM_EPOCHS = 10\n",
            "LEARNING_RATE = 0.001\n",
            "\n",
            "üìÅ VERIFICACI√ìN DE DIRECTORIOS:\n",
            "¬øExiste DATA_DIR? ‚úÖ S√ç\n",
            "¬øExiste TEST_DIR? ‚úÖ S√ç\n",
            "¬øExiste OUTPUT_DIR? ‚úÖ S√ç\n",
            "\n",
            "üìÇ CONTENIDO DE DIRECTORIOS DE ENTRENAMIENTO:\n",
            "Carpetas en DATA_DIR: ['tardienta', 'ter', 'talgo']\n",
            "\n",
            "Clase 'talgo':\n",
            "  - Ruta: /content/train_images/talgo\n",
            "  - Total archivos: 63\n",
            "  - Archivos de imagen: 63\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase 'tardienta':\n",
            "  - Ruta: /content/train_images/tardienta\n",
            "  - Total archivos: 39\n",
            "  - Archivos de imagen: 39\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase 'ter':\n",
            "  - Ruta: /content/train_images/ter\n",
            "  - Total archivos: 60\n",
            "  - Archivos de imagen: 59\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "üìÇ CONTENIDO DE DIRECTORIOS DE PRUEBA:\n",
            "Carpetas en TEST_DIR: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo', 'otros']\n",
            "\n",
            "Clase de prueba 'talgo':\n",
            "  - Ruta: /content/test_images/talgo\n",
            "  - Total archivos: 22\n",
            "  - Archivos de imagen: 22\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'tardienta':\n",
            "  - Ruta: /content/test_images/tardienta\n",
            "  - Total archivos: 19\n",
            "  - Archivos de imagen: 19\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'ter':\n",
            "  - Ruta: /content/test_images/ter\n",
            "  - Total archivos: 29\n",
            "  - Archivos de imagen: 29\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'otros':\n",
            "  - Ruta: /content/test_images/otros\n",
            "  - Total archivos: 37\n",
            "  - Archivos de imagen: 37\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "‚úÖ DIAGN√ìSTICO COMPLETADO\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "üöÄ INICIANDO PROCESO DE ENTRENAMIENTO\n",
            "==================================================\n",
            "Cargando dataset desde: /content/train_images\n",
            "Clases seleccionadas: ['talgo', 'tardienta', 'ter']\n",
            "Clases disponibles en /content/train_images: ['tardienta', 'ter', 'talgo']\n",
            "üîç Filtrando solo las clases: ['talgo', 'tardienta', 'ter']\n",
            "Dataset completo cargado con clases: ['talgo', 'tardienta', 'ter']\n",
            "Mapeo de clases a √≠ndices: {'talgo': 0, 'tardienta': 1, 'ter': 2}\n",
            "√çndices seleccionados: 161 de 161\n",
            "‚úÖ Dataset filtrado creado con 161 im√°genes\n",
            "Dividiendo dataset en entrenamiento (80%) y validaci√≥n (20%)\n",
            "Dataset original: 161 im√°genes\n",
            "√çndices de entrenamiento: 129 im√°genes\n",
            "√çndices de validaci√≥n: 32 im√°genes\n",
            "‚úÖ Dataset dividido: 129 im√°genes para entrenamiento, 32 im√°genes para validaci√≥n\n",
            "Creando dataloaders con batch_size=16, num_workers=2\n",
            "‚úÖ Dataloaders creados:\n",
            "   Train loader: 9 lotes\n",
            "   Val loader: 2 lotes\n",
            "Cargando modelo efficientnet_b0 para 3 clases\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 109MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo efficientnet_b0 cargado y adaptado para 3 clases\n",
            "\n",
            "==================================================\n",
            "üöÇ INICIANDO ENTRENAMIENTO DEL MODELO\n",
            "==================================================\n",
            "\n",
            "üìä VERIFICACI√ìN DE DATALOADERS:\n",
            "Train loader: 9 lotes (batch_size=16)\n",
            "Val loader: 2 lotes (batch_size=16)\n",
            "\n",
            "üîç VERIFICANDO MUESTRA DE DATOS:\n",
            "Forma del lote de im√°genes: torch.Size([16, 3, 224, 224])\n",
            "Forma de las etiquetas: torch.Size([16])\n",
            "Rango de valores de las im√°genes: [-2.1179, 2.6400]\n",
            "Etiquetas en el lote: [0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2]\n",
            "\n",
            "==================== √âpoca 1/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 1...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.6636 | Precisi√≥n: 80.00% | Tiempo: 17.50s\n",
            "  Lote 9/9 | P√©rdida: 0.6421 | Precisi√≥n: 86.82% | Tiempo: 23.01s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 1...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 1:\n",
            "  Entrenamiento - P√©rdida: 0.6421, Precisi√≥n: 86.82%\n",
            "  Validaci√≥n - P√©rdida: 0.0873, Precisi√≥n: 96.88%\n",
            "  üíæ Guardando mejor modelo (precisi√≥n: 96.88%)\n",
            "\n",
            "==================== √âpoca 2/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 2...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0767 | Precisi√≥n: 97.50% | Tiempo: 16.44s\n",
            "  Lote 9/9 | P√©rdida: 0.1706 | Precisi√≥n: 97.67% | Tiempo: 22.72s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 2...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 2:\n",
            "  Entrenamiento - P√©rdida: 0.1706, Precisi√≥n: 97.67%\n",
            "  Validaci√≥n - P√©rdida: 0.0001, Precisi√≥n: 100.00%\n",
            "  üíæ Guardando mejor modelo (precisi√≥n: 100.00%)\n",
            "\n",
            "==================== √âpoca 3/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 3...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0190 | Precisi√≥n: 100.00% | Tiempo: 16.47s\n",
            "  Lote 9/9 | P√©rdida: 0.2281 | Precisi√≥n: 97.67% | Tiempo: 22.88s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 3...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 3:\n",
            "  Entrenamiento - P√©rdida: 0.2281, Precisi√≥n: 97.67%\n",
            "  Validaci√≥n - P√©rdida: 0.0015, Precisi√≥n: 100.00%\n",
            "\n",
            "==================== √âpoca 4/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 4...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0127 | Precisi√≥n: 100.00% | Tiempo: 16.87s\n",
            "  Lote 9/9 | P√©rdida: 0.0905 | Precisi√≥n: 100.00% | Tiempo: 23.08s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 4...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 4:\n",
            "  Entrenamiento - P√©rdida: 0.0905, Precisi√≥n: 100.00%\n",
            "  Validaci√≥n - P√©rdida: 0.0016, Precisi√≥n: 100.00%\n",
            "\n",
            "==================== √âpoca 5/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 5...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0758 | Precisi√≥n: 95.00% | Tiempo: 17.49s\n",
            "  Lote 9/9 | P√©rdida: 0.1692 | Precisi√≥n: 94.57% | Tiempo: 22.72s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 5...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 5:\n",
            "  Entrenamiento - P√©rdida: 0.1692, Precisi√≥n: 94.57%\n",
            "  Validaci√≥n - P√©rdida: 0.0216, Precisi√≥n: 100.00%\n",
            "\n",
            "==================== √âpoca 6/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 6...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0854 | Precisi√≥n: 98.75% | Tiempo: 16.27s\n",
            "  Lote 9/9 | P√©rdida: 0.0826 | Precisi√≥n: 99.22% | Tiempo: 21.69s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 6...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 6:\n",
            "  Entrenamiento - P√©rdida: 0.0826, Precisi√≥n: 99.22%\n",
            "  Validaci√≥n - P√©rdida: 0.0805, Precisi√≥n: 96.88%\n",
            "\n",
            "==================== √âpoca 7/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 7...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0576 | Precisi√≥n: 97.50% | Tiempo: 16.50s\n",
            "  Lote 9/9 | P√©rdida: 0.4044 | Precisi√≥n: 96.12% | Tiempo: 22.40s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 7...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 7:\n",
            "  Entrenamiento - P√©rdida: 0.4044, Precisi√≥n: 96.12%\n",
            "  Validaci√≥n - P√©rdida: 0.0040, Precisi√≥n: 100.00%\n",
            "\n",
            "==================== √âpoca 8/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 8...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0204 | Precisi√≥n: 100.00% | Tiempo: 16.45s\n",
            "  Lote 9/9 | P√©rdida: 0.0862 | Precisi√≥n: 100.00% | Tiempo: 22.75s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 8...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 8:\n",
            "  Entrenamiento - P√©rdida: 0.0862, Precisi√≥n: 100.00%\n",
            "  Validaci√≥n - P√©rdida: 0.1947, Precisi√≥n: 90.62%\n",
            "\n",
            "==================== √âpoca 9/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 9...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.2167 | Precisi√≥n: 96.25% | Tiempo: 16.82s\n",
            "  Lote 9/9 | P√©rdida: 0.2845 | Precisi√≥n: 96.90% | Tiempo: 22.80s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 9...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 9:\n",
            "  Entrenamiento - P√©rdida: 0.2845, Precisi√≥n: 96.90%\n",
            "  Validaci√≥n - P√©rdida: 0.1429, Precisi√≥n: 93.75%\n",
            "\n",
            "==================== √âpoca 10/10 ====================\n",
            "‚è≥ Iniciando entrenamiento de √©poca 10...\n",
            "‚úÖ Primer lote cargado correctamente\n",
            "  Lote 5/9 | P√©rdida: 0.0270 | Precisi√≥n: 98.75% | Tiempo: 17.63s\n",
            "  Lote 9/9 | P√©rdida: 0.0983 | Precisi√≥n: 96.12% | Tiempo: 22.91s\n",
            "\n",
            "‚è≥ Iniciando evaluaci√≥n de √©poca 10...\n",
            "‚úÖ Primer lote de validaci√≥n cargado correctamente\n",
            "\n",
            "üìä Resultados de √©poca 10:\n",
            "  Entrenamiento - P√©rdida: 0.0983, Precisi√≥n: 96.12%\n",
            "  Validaci√≥n - P√©rdida: 0.0856, Precisi√≥n: 93.75%\n",
            "\n",
            "‚úÖ ENTRENAMIENTO COMPLETADO\n",
            "Mejor precisi√≥n de validaci√≥n: 100.00%\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando el mejor modelo desde /content/output/models/best_model.pth\n",
            "Cargando dataset desde: /content/test_images\n",
            "Clases seleccionadas: ['talgo', 'tardienta', 'ter']\n",
            "Clases disponibles en /content/test_images: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo', 'otros']\n",
            "üîç Filtrando solo las clases: ['talgo', 'tardienta', 'ter']\n",
            "‚ùå Error al cargar el dataset: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
            "\n",
            "==================================================\n",
            "üì¶ EXPORTANDO MODELO A ONNX\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-37-3abc60935ae2>\", line 206, in load_dataset\n",
            "    full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 328, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 150, in __init__\n",
            "    samples = self.make_dataset(\n",
            "              ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 203, in make_dataset\n",
            "    return make_dataset(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\", line 104, in make_dataset\n",
            "    raise FileNotFoundError(msg)\n",
            "FileNotFoundError: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo exportado a ONNX: /content/output/models/efficientnet_model.onnx\n",
            "üîç Probando inferencia con ONNX Runtime...\n",
            "‚úÖ Inferencia con ONNX Runtime exitosa\n",
            "   Forma de la salida: (1, 3)\n",
            "\n",
            "==================================================\n",
            "‚úÖ PROCESO COMPLETADO EXITOSAMENTE\n",
            "==================================================\n",
            "\n",
            "üìÅ Archivos generados:\n",
            "   - Modelo ONNX: /content/output/models/efficientnet_model.onnx\n",
            "   - Embeddings: /content/output/embeddings/dataset_embeddings.json\n",
            "   - Visualizaciones: /content/output/visualizations/training_curves.png\n",
            "\n",
            "üîç Estos archivos son necesarios para usar el script compare_image_onnx.js\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d15ab5b1",
      "metadata": {
        "id": "d15ab5b1"
      },
      "source": [
        "\n",
        "# Entrenamiento de Modelo para Clasificaci√≥n de Trenes - Versi√≥n para Principiantes\n",
        "\n",
        "Este notebook implementa un sistema de reconocimiento visual para diferenciar entre distintos tipos de trenes mediante fotograf√≠as.\n",
        "Est√° dise√±ado para ser f√°cil de seguir incluso si no tienes experiencia previa en deep learning.\n",
        "\n",
        "## ¬øQu√© hace este notebook?\n",
        "Este notebook te ayudar√° a crear un modelo que puede distinguir entre diferentes tipos de trenes (inicialmente TALGO, TER y TARDIENTA)\n",
        "y rechazar correctamente im√°genes que no pertenecen a ninguna de estas clases.\n",
        "\n",
        "## Paso a paso:\n",
        "1. Cargar im√°genes de trenes organizadas en carpetas\n",
        "2. Preparar las im√°genes para el entrenamiento (redimensionar, aumentar datos)\n",
        "3. Crear y entrenar un modelo de deep learning\n",
        "4. Extraer \"embeddings\" (representaciones num√©ricas) de las im√°genes\n",
        "5. Evaluar qu√© tan bien funciona el modelo\n",
        "6. Guardar el modelo para usarlo despu√©s\n",
        "\n",
        "Autor: Manus\n",
        "Fecha: Abril 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ec7d18",
      "metadata": {
        "id": "58ec7d18"
      },
      "source": [
        "# # Primero, ejecuta esta celda para instalar las bibliotecas necesarias si no est√°n ya instaladas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision onnx onnxruntime scikit-learn matplotlib seaborn tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrh7yjvqCKNg",
        "outputId": "c91c099a-29e5-44c7-95e4-e1f3cde57ac7"
      },
      "id": "vrh7yjvqCKNg",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/train_images/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "OWZvFxDlCdkw"
      },
      "id": "OWZvFxDlCdkw",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uoE9xHQ0CgIn"
      },
      "id": "uoE9xHQ0CgIn"
    },
    {
      "cell_type": "markdown",
      "id": "8b22a1b3",
      "metadata": {
        "id": "8b22a1b3"
      },
      "source": [
        "!pip install torch torchvision onnx onnxruntime scikit-learn matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y_k_UC11Nu6",
        "outputId": "4df73cfc-4f49-4e99-cd7d-b8aaf1b40e37"
      },
      "id": "-y_k_UC11Nu6",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d0e43da4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0e43da4",
        "outputId": "52812276-96e9-4998-e93f-a5ce3e57aa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilizando dispositivo: cuda\n",
            "üîç Si ves 'cuda', est√°s usando una GPU. Si ves 'cpu', est√°s usando la CPU.\n",
            "‚úÖ Configuraci√≥n inicial completada\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm  # Para mostrar barras de progreso\n",
        "import pickle\n",
        "import json\n",
        "from pathlib import Path\n",
        "import time\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms, datasets\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import onnx\n",
        "import onnxruntime\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Fija las semillas aleatorias para que los resultados sean reproducibles.\n",
        "    Esto es importante para experimentos cient√≠ficos.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()  # Aplicamos la configuraci√≥n de semillas\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilizando dispositivo: {device}\")\n",
        "print(f\"üîç Si ves 'cuda', est√°s usando una GPU. Si ves 'cpu', est√°s usando la CPU.\")\n",
        "\n",
        "class Config:\n",
        "    \"\"\"\n",
        "    Esta clase contiene todos los ajustes que usaremos para entrenar nuestro modelo.\n",
        "    Puedes modificar estos valores seg√∫n tus necesidades.\n",
        "    \"\"\"\n",
        "    # Rutas (ajusta estas rutas seg√∫n donde subas tus im√°genes)\n",
        "    DATA_DIR = \"/content/train_images\"  # Carpeta con im√°genes de entrenamiento\n",
        "    TEST_DIR = \"/content/test_images\"   # Carpeta con im√°genes de prueba\n",
        "    OUTPUT_DIR = \"/content/output\"      # Carpeta para guardar resultados\n",
        "\n",
        "    # Clases iniciales para el enfoque incremental\n",
        "    SELECTED_CLASSES = [\"talgo\", \"ter\", \"tardienta\"]  # Empezamos con estas 3 clases\n",
        "\n",
        "    # Par√°metros de entrenamiento\n",
        "    BATCH_SIZE = 32            # N√∫mero de im√°genes procesadas a la vez\n",
        "    NUM_EPOCHS = 30            # N√∫mero m√°ximo de pasadas completas por los datos\n",
        "    LEARNING_RATE = 1e-4       # Qu√© tan r√°pido aprende el modelo (m√°s bajo = m√°s lento pero m√°s estable)\n",
        "    WEIGHT_DECAY = 1e-5        # Regularizaci√≥n para evitar sobreajuste\n",
        "\n",
        "    # Arquitectura\n",
        "    MODEL_NAME = \"efficientnet\"  # Modelo base (opciones: \"efficientnet\", \"resnet50\")\n",
        "    EMBEDDING_SIZE = 1280        # Tama√±o del embedding (depende del modelo)\n",
        "\n",
        "    # Preprocesamiento\n",
        "    IMG_SIZE = 224               # Tama√±o al que redimensionaremos todas las im√°genes\n",
        "\n",
        "    # Entrenamiento\n",
        "    VALIDATION_SPLIT = 0.2       # Porcentaje de datos usados para validaci√≥n\n",
        "    EARLY_STOPPING_PATIENCE = 5  # Cu√°ntas √©pocas esperar antes de detener si no hay mejora\n",
        "\n",
        "    # Optimizaci√≥n\n",
        "    USE_MIXED_PRECISION = True   # Usar precisi√≥n mixta para acelerar entrenamiento\n",
        "\n",
        "    # Exportaci√≥n\n",
        "    EXPORT_FORMAT = \"onnx\"       # Formato para exportar el modelo\n",
        "\n",
        "config = Config()  # Creamos una instancia de la configuraci√≥n\n",
        "\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"models\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"embeddings\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(config.OUTPUT_DIR, \"visualizations\"), exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Configuraci√≥n inicial completada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9695619",
      "metadata": {
        "id": "b9695619"
      },
      "source": [
        "# # Transformaciones para data augmentation (crear variaciones de las im√°genes para mejorar el aprendizaje)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "9ea24924",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ea24924",
        "outputId": "ae0a0790-159d-4e85-efc6-01ca6471e0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funciones de preparaci√≥n de datos definidas\n"
          ]
        }
      ],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),  # Redimensionar todas las im√°genes al mismo tama√±o\n",
        "    transforms.RandomHorizontalFlip(p=0.5),                 # Voltear horizontalmente con 50% de probabilidad\n",
        "    transforms.RandomRotation(degrees=10),                  # Rotar ligeramente\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Variar colores\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),     # Peque√±as deformaciones\n",
        "    transforms.ToTensor(),                                  # Convertir a tensor (formato que usa PyTorch)\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],        # Normalizar valores de p√≠xeles\n",
        "                         std=[0.229, 0.224, 0.225])         # (estos son valores est√°ndar para im√°genes)\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),  # Redimensionar\n",
        "    transforms.ToTensor(),                                  # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],        # Normalizar\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Funci√≥n para cargar el dataset desde carpetas\n",
        "def load_dataset(data_dir, transform=None, selected_classes=None):\n",
        "    \"\"\"\n",
        "    Carga un dataset de im√°genes organizadas en carpetas por clase.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directorio con las im√°genes organizadas en subcarpetas por clase\n",
        "        transform: Transformaciones a aplicar a las im√°genes\n",
        "        selected_classes: Lista de clases espec√≠ficas a incluir (None = todas)\n",
        "\n",
        "    Returns:\n",
        "        dataset: Dataset cargado\n",
        "        class_names: Nombres de las clases\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Si tenemos clases seleccionadas, filtramos solo esas carpetas\n",
        "        if selected_classes:\n",
        "            # Verificar qu√© clases est√°n disponibles en el directorio\n",
        "            available_classes = [d for d in os.listdir(data_dir)\n",
        "                               if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "            print(f\"Clases disponibles en {data_dir}: {available_classes}\")\n",
        "\n",
        "            # Filtrar solo las clases seleccionadas que est√°n disponibles\n",
        "            valid_classes = [c for c in selected_classes if c in available_classes]\n",
        "\n",
        "            if not valid_classes:\n",
        "                print(f\"‚ö†Ô∏è Ninguna de las clases seleccionadas {selected_classes} est√° disponible en {data_dir}\")\n",
        "                print(f\"‚ö†Ô∏è Usando todas las clases disponibles\")\n",
        "                dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "            else:\n",
        "                print(f\"üîç Filtrando solo las clases: {valid_classes}\")\n",
        "\n",
        "                # Crear un dataset personalizado con solo las clases seleccionadas\n",
        "                # Primero cargamos todo el dataset para obtener la estructura\n",
        "                full_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "                # Luego filtramos solo las clases que nos interesan\n",
        "                selected_indices = [i for i, (_, label) in enumerate(full_dataset.samples)\n",
        "                                  if full_dataset.classes[label] in valid_classes]\n",
        "\n",
        "                # Creamos un subconjunto con solo esas clases\n",
        "                from torch.utils.data import Subset\n",
        "                dataset = Subset(full_dataset, selected_indices)\n",
        "\n",
        "                # Ajustamos las clases\n",
        "                dataset.classes = valid_classes\n",
        "                dataset.class_to_idx = {cls: i for i, cls in enumerate(valid_classes)}\n",
        "\n",
        "                # Para mantener la compatibilidad con ImageFolder\n",
        "                class_names = valid_classes\n",
        "                print(f\"‚úÖ Dataset filtrado: {len(selected_indices)} im√°genes de {len(valid_classes)} clases\")\n",
        "                return dataset, class_names\n",
        "        else:\n",
        "            # Si no hay filtro, cargamos todas las clases\n",
        "            dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "        class_names = dataset.classes\n",
        "        print(f\"‚úÖ Dataset cargado con {len(dataset)} im√°genes y {len(class_names)} clases\")\n",
        "        print(f\"üè∑Ô∏è Clases: {class_names}\")\n",
        "        return dataset, class_names\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al cargar el dataset: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Funci√≥n para dividir el dataset en entrenamiento y validaci√≥n\n",
        "def split_dataset(dataset, val_split=0.2, seed=42):\n",
        "    \"\"\"\n",
        "    Divide un dataset en conjuntos de entrenamiento y validaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        dataset: Dataset completo\n",
        "        val_split: Proporci√≥n para validaci√≥n (0.2 = 20%)\n",
        "        seed: Semilla aleatoria para reproducibilidad\n",
        "\n",
        "    Returns:\n",
        "        train_dataset: Conjunto de entrenamiento\n",
        "        val_dataset: Conjunto de validaci√≥n\n",
        "    \"\"\"\n",
        "    # Obtener √≠ndices de todas las muestras\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    # Dividir √≠ndices en entrenamiento y validaci√≥n\n",
        "    val_size = int(val_split * len(indices))\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[val_size:], indices[:val_size]\n",
        "\n",
        "    # Crear subconjuntos\n",
        "    from torch.utils.data import Subset\n",
        "    train_dataset = Subset(dataset, train_indices)\n",
        "    val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "    print(f\"‚úÖ Dataset dividido: {len(train_dataset)} im√°genes para entrenamiento, {len(val_dataset)} im√°genes para validaci√≥n\")\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# Funci√≥n para crear dataloaders (cargadores de datos para el entrenamiento)\n",
        "def create_dataloaders(train_dataset, val_dataset, batch_size=32, num_workers=2):\n",
        "    \"\"\"\n",
        "    Crea dataloaders para entrenamiento y validaci√≥n.\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Conjunto de entrenamiento\n",
        "        val_dataset: Conjunto de validaci√≥n\n",
        "        batch_size: Tama√±o del lote (cu√°ntas im√°genes procesar a la vez)\n",
        "        num_workers: N√∫mero de hilos para cargar datos (ajustar seg√∫n CPU)\n",
        "\n",
        "    Returns:\n",
        "        train_loader: Dataloader para entrenamiento\n",
        "        val_loader: Dataloader para validaci√≥n\n",
        "    \"\"\"\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,              # Mezclar datos en cada √©poca\n",
        "        num_workers=num_workers,   # Hilos para cargar datos\n",
        "        pin_memory=True            # Mejora rendimiento con GPU\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,             # No es necesario mezclar datos de validaci√≥n\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "print(\"‚úÖ Funciones de preparaci√≥n de datos definidas\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero definimos las variables de configuraci√≥n\n",
        "DATA_DIR = \"/content/train_images\"\n",
        "TEST_DIR = \"/content/test_images\"\n",
        "OUTPUT_DIR = \"/content/output\"\n",
        "SELECTED_CLASSES = [\"talgo\", \"tardienta\", \"ter\"]\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Ahora ejecutamos el diagn√≥stico\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"üîç DIAGN√ìSTICO COMPLETO DEL ENTORNO Y DATASET\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Verificar configuraci√≥n\n",
        "print(\"\\nüìã CONFIGURACI√ìN ACTUAL:\")\n",
        "print(f\"DATA_DIR = '{DATA_DIR}'\")\n",
        "print(f\"TEST_DIR = '{TEST_DIR}'\")\n",
        "print(f\"OUTPUT_DIR = '{OUTPUT_DIR}'\")\n",
        "print(f\"SELECTED_CLASSES = {SELECTED_CLASSES}\")\n",
        "print(f\"BATCH_SIZE = {BATCH_SIZE}\")\n",
        "print(f\"NUM_EPOCHS = {NUM_EPOCHS}\")\n",
        "print(f\"LEARNING_RATE = {LEARNING_RATE}\")\n",
        "\n",
        "# Verificar existencia de directorios\n",
        "print(\"\\nüìÅ VERIFICACI√ìN DE DIRECTORIOS:\")\n",
        "print(f\"¬øExiste DATA_DIR? {'‚úÖ S√ç' if os.path.exists(DATA_DIR) else '‚ùå NO'}\")\n",
        "print(f\"¬øExiste TEST_DIR? {'‚úÖ S√ç' if os.path.exists(TEST_DIR) else '‚ùå NO'}\")\n",
        "print(f\"¬øExiste OUTPUT_DIR? {'‚úÖ S√ç' if os.path.exists(OUTPUT_DIR) else '‚ùå NO'}\")\n",
        "\n",
        "# Verificar contenido de directorios de entrenamiento\n",
        "print(\"\\nüìÇ CONTENIDO DE DIRECTORIOS DE ENTRENAMIENTO:\")\n",
        "if os.path.exists(DATA_DIR):\n",
        "    all_dirs = os.listdir(DATA_DIR)\n",
        "    print(f\"Carpetas en DATA_DIR: {all_dirs}\")\n",
        "\n",
        "    for class_name in SELECTED_CLASSES:\n",
        "        class_path = os.path.join(DATA_DIR, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            files = os.listdir(class_path)\n",
        "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            print(f\"\\nClase '{class_name}':\")\n",
        "            print(f\"  - Ruta: {class_path}\")\n",
        "            print(f\"  - Total archivos: {len(files)}\")\n",
        "            print(f\"  - Archivos de imagen: {len(image_files)}\")\n",
        "\n",
        "            # Intentar abrir una imagen para verificar que sea v√°lida\n",
        "            if image_files:\n",
        "                try:\n",
        "                    img_path = os.path.join(class_path, image_files[0])\n",
        "                    img = Image.open(img_path)\n",
        "                    print(f\"  - Prueba de imagen: ‚úÖ Imagen v√°lida ({img.size[0]}x{img.size[1]})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  - Prueba de imagen: ‚ùå Error al abrir imagen: {e}\")\n",
        "            else:\n",
        "                print(f\"  - ‚ö†Ô∏è No hay archivos de imagen en esta carpeta\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå La carpeta para la clase '{class_name}' no existe en {DATA_DIR}\")\n",
        "\n",
        "# Verificar contenido de directorios de prueba\n",
        "print(\"\\nüìÇ CONTENIDO DE DIRECTORIOS DE PRUEBA:\")\n",
        "if os.path.exists(TEST_DIR):\n",
        "    all_dirs = os.listdir(TEST_DIR)\n",
        "    print(f\"Carpetas en TEST_DIR: {all_dirs}\")\n",
        "\n",
        "    for class_name in SELECTED_CLASSES + [\"otros\"]:\n",
        "        class_path = os.path.join(TEST_DIR, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            files = os.listdir(class_path)\n",
        "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            print(f\"\\nClase de prueba '{class_name}':\")\n",
        "            print(f\"  - Ruta: {class_path}\")\n",
        "            print(f\"  - Total archivos: {len(files)}\")\n",
        "            print(f\"  - Archivos de imagen: {len(image_files)}\")\n",
        "\n",
        "            # Intentar abrir una imagen para verificar que sea v√°lida\n",
        "            if image_files:\n",
        "                try:\n",
        "                    img_path = os.path.join(class_path, image_files[0])\n",
        "                    img = Image.open(img_path)\n",
        "                    print(f\"  - Prueba de imagen: ‚úÖ Imagen v√°lida ({img.size[0]}x{img.size[1]})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  - Prueba de imagen: ‚ùå Error al abrir imagen: {e}\")\n",
        "            else:\n",
        "                print(f\"  - ‚ö†Ô∏è No hay archivos de imagen en esta carpeta\")\n",
        "        else:\n",
        "            print(f\"\\n‚ùå La carpeta para la clase '{class_name}' no existe en {TEST_DIR}\")\n",
        "\n",
        "print(\"\\n‚úÖ DIAGN√ìSTICO COMPLETADO\")\n",
        "print(\"=\"*50)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pET2LDR3-UgR",
        "outputId": "01788d6d-76a9-4fa8-9cfe-7ea972016460"
      },
      "id": "pET2LDR3-UgR",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "üîç DIAGN√ìSTICO COMPLETO DEL ENTORNO Y DATASET\n",
            "==================================================\n",
            "\n",
            "üìã CONFIGURACI√ìN ACTUAL:\n",
            "DATA_DIR = '/content/train_images'\n",
            "TEST_DIR = '/content/test_images'\n",
            "OUTPUT_DIR = '/content/output'\n",
            "SELECTED_CLASSES = ['talgo', 'tardienta', 'ter']\n",
            "BATCH_SIZE = 32\n",
            "NUM_EPOCHS = 10\n",
            "LEARNING_RATE = 0.001\n",
            "\n",
            "üìÅ VERIFICACI√ìN DE DIRECTORIOS:\n",
            "¬øExiste DATA_DIR? ‚úÖ S√ç\n",
            "¬øExiste TEST_DIR? ‚úÖ S√ç\n",
            "¬øExiste OUTPUT_DIR? ‚úÖ S√ç\n",
            "\n",
            "üìÇ CONTENIDO DE DIRECTORIOS DE ENTRENAMIENTO:\n",
            "Carpetas en DATA_DIR: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo']\n",
            "\n",
            "Clase 'talgo':\n",
            "  - Ruta: /content/train_images/talgo\n",
            "  - Total archivos: 63\n",
            "  - Archivos de imagen: 63\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase 'tardienta':\n",
            "  - Ruta: /content/train_images/tardienta\n",
            "  - Total archivos: 39\n",
            "  - Archivos de imagen: 39\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase 'ter':\n",
            "  - Ruta: /content/train_images/ter\n",
            "  - Total archivos: 60\n",
            "  - Archivos de imagen: 59\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "üìÇ CONTENIDO DE DIRECTORIOS DE PRUEBA:\n",
            "Carpetas en TEST_DIR: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo', 'otros']\n",
            "\n",
            "Clase de prueba 'talgo':\n",
            "  - Ruta: /content/test_images/talgo\n",
            "  - Total archivos: 22\n",
            "  - Archivos de imagen: 22\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'tardienta':\n",
            "  - Ruta: /content/test_images/tardienta\n",
            "  - Total archivos: 19\n",
            "  - Archivos de imagen: 19\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'ter':\n",
            "  - Ruta: /content/test_images/ter\n",
            "  - Total archivos: 29\n",
            "  - Archivos de imagen: 29\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "Clase de prueba 'otros':\n",
            "  - Ruta: /content/test_images/otros\n",
            "  - Total archivos: 37\n",
            "  - Archivos de imagen: 37\n",
            "  - Prueba de imagen: ‚úÖ Imagen v√°lida (4096x3072)\n",
            "\n",
            "‚úÖ DIAGN√ìSTICO COMPLETADO\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fbf9470",
      "metadata": {
        "id": "8fbf9470"
      },
      "source": [
        "# # Clase para el modelo de embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f3dadef9",
      "metadata": {
        "id": "f3dadef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab87629e-4a13-4f67-853f-1bc2e333f443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modelo definido\n"
          ]
        }
      ],
      "source": [
        "class EmbeddingModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo para extraer embeddings y clasificar im√°genes.\n",
        "\n",
        "    Este modelo usa una red pre-entrenada (backbone) para extraer caracter√≠sticas,\n",
        "    y luego a√±ade una capa de clasificaci√≥n para nuestras clases espec√≠ficas.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, num_classes, embedding_size=None, pretrained=True):\n",
        "        \"\"\"\n",
        "        Inicializa el modelo.\n",
        "\n",
        "        Args:\n",
        "            model_name: Nombre del modelo base (\"efficientnet\", \"resnet50\")\n",
        "            num_classes: N√∫mero de clases a clasificar\n",
        "            embedding_size: Tama√±o del embedding (si None, se determina autom√°ticamente)\n",
        "            pretrained: Si usar pesos pre-entrenados (transfer learning)\n",
        "        \"\"\"\n",
        "        super(EmbeddingModel, self).__init__()\n",
        "        self.model_name = model_name\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        # Seleccionar backbone seg√∫n el modelo especificado\n",
        "        if model_name == \"efficientnet\":\n",
        "            # EfficientNet es un modelo moderno y eficiente\n",
        "            self.backbone = models.efficientnet_b0(pretrained=pretrained)\n",
        "            self.embedding_size = self.backbone.classifier[1].in_features\n",
        "            self.backbone.classifier = nn.Identity()  # Quitamos la capa de clasificaci√≥n original\n",
        "\n",
        "        elif model_name == \"resnet50\":\n",
        "            # ResNet50 es un modelo cl√°sico muy potente\n",
        "            self.backbone = models.resnet50(pretrained=pretrained)\n",
        "            self.embedding_size = self.backbone.fc.in_features\n",
        "            self.backbone.fc = nn.Identity()  # Quitamos la capa de clasificaci√≥n original\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"‚ùå Modelo {model_name} no soportado\")\n",
        "\n",
        "        # Capa de clasificaci√≥n para nuestras clases espec√≠ficas\n",
        "        self.classifier = nn.Linear(self.embedding_size, num_classes)\n",
        "\n",
        "        # Normalizaci√≥n L2 para embeddings (hace que la comparaci√≥n por similitud funcione mejor)\n",
        "        self.normalize = lambda x: F.normalize(x, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x, return_embeddings=False):\n",
        "        \"\"\"\n",
        "        Pasa una imagen por el modelo.\n",
        "\n",
        "        Args:\n",
        "            x: Tensor de imagen de entrada\n",
        "            return_embeddings: Si devolver tambi√©n los embeddings\n",
        "\n",
        "        Returns:\n",
        "            logits: Puntuaciones para cada clase\n",
        "            embeddings: (Opcional) Embeddings normalizados\n",
        "        \"\"\"\n",
        "        # Extraer caracter√≠sticas usando el backbone\n",
        "        embeddings = self.backbone(x)\n",
        "\n",
        "        # Normalizar embeddings (para que tengan norma 1)\n",
        "        normalized_embeddings = self.normalize(embeddings)\n",
        "\n",
        "        # Clasificaci√≥n\n",
        "        logits = self.classifier(normalized_embeddings)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return logits, normalized_embeddings\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "    def extract_embeddings(self, x):\n",
        "        \"\"\"\n",
        "        Extrae embeddings normalizados de una imagen.\n",
        "\n",
        "        Args:\n",
        "            x: Tensor de imagen de entrada\n",
        "\n",
        "        Returns:\n",
        "            normalized_embeddings: Embeddings normalizados\n",
        "        \"\"\"\n",
        "        self.eval()  # Poner modelo en modo evaluaci√≥n\n",
        "        with torch.no_grad():  # No calcular gradientes (m√°s eficiente)\n",
        "            embeddings = self.backbone(x)\n",
        "            normalized_embeddings = self.normalize(embeddings)\n",
        "        return normalized_embeddings\n",
        "\n",
        "print(\"‚úÖ Modelo definido\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DIAGN√ìSTICO FORZADO DEL PROCESO DE ENTRENAMIENTO\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üîç DIAGN√ìSTICO FORZADO DEL PROCESO DE ENTRENAMIENTO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Verificar que los datasets se carguen correctamente\n",
        "print(\"\\n1Ô∏è‚É£ VERIFICANDO CARGA DE DATASETS:\")\n",
        "try:\n",
        "    print(f\"Intentando cargar dataset de entrenamiento desde: {DATA_DIR}\")\n",
        "    train_dataset, class_names = load_dataset(DATA_DIR, transform=train_transforms, selected_classes=SELECTED_CLASSES)\n",
        "    print(f\"‚úÖ Dataset de entrenamiento cargado: {train_dataset}\")\n",
        "\n",
        "    if hasattr(train_dataset, '__len__'):\n",
        "        print(f\"   Tama√±o del dataset: {len(train_dataset)} im√°genes\")\n",
        "    else:\n",
        "        print(f\"   El dataset no tiene m√©todo __len__, verificando si es un Subset\")\n",
        "        if hasattr(train_dataset, 'dataset') and hasattr(train_dataset, 'indices'):\n",
        "            print(f\"   Es un Subset con {len(train_dataset.indices)} im√°genes\")\n",
        "\n",
        "    print(f\"   Clases: {class_names}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR al cargar dataset de entrenamiento: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 2. Verificar la divisi√≥n train/val\n",
        "print(\"\\n2Ô∏è‚É£ VERIFICANDO DIVISI√ìN TRAIN/VAL:\")\n",
        "try:\n",
        "    if 'train_dataset' in locals():\n",
        "        print(f\"Dividiendo dataset en entrenamiento y validaci√≥n...\")\n",
        "        train_subset, val_subset = split_dataset(train_dataset, val_split=0.2)\n",
        "        print(f\"‚úÖ Divisi√≥n completada:\")\n",
        "        print(f\"   Train subset: {len(train_subset)} im√°genes\")\n",
        "        print(f\"   Val subset: {len(val_subset)} im√°genes\")\n",
        "    else:\n",
        "        print(\"‚ùå No se puede dividir porque el dataset de entrenamiento no se carg√≥ correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR al dividir dataset: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 3. Verificar la creaci√≥n de dataloaders\n",
        "print(\"\\n3Ô∏è‚É£ VERIFICANDO CREACI√ìN DE DATALOADERS:\")\n",
        "try:\n",
        "    if 'train_subset' in locals() and 'val_subset' in locals():\n",
        "        print(f\"Creando dataloaders con batch_size={BATCH_SIZE}...\")\n",
        "        train_loader, val_loader = create_dataloaders(train_subset, val_subset, batch_size=BATCH_SIZE)\n",
        "        print(f\"‚úÖ Dataloaders creados:\")\n",
        "        print(f\"   Train loader: {len(train_loader)} lotes\")\n",
        "        print(f\"   Val loader: {len(val_loader)} lotes\")\n",
        "    else:\n",
        "        print(\"‚ùå No se pueden crear dataloaders porque la divisi√≥n train/val no se complet√≥ correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR al crear dataloaders: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "# 4. Verificar una muestra del dataloader\n",
        "print(\"\\n4Ô∏è‚É£ VERIFICANDO MUESTRA DE DATOS:\")\n",
        "try:\n",
        "    if 'train_loader' in locals():\n",
        "        print(f\"Intentando obtener una muestra del dataloader...\")\n",
        "        train_iter = iter(train_loader)\n",
        "        sample_batch, sample_labels = next(train_iter)\n",
        "        print(f\"‚úÖ Muestra obtenida:\")\n",
        "        print(f\"   Forma del lote de im√°genes: {sample_batch.shape}\")\n",
        "        print(f\"   Forma de las etiquetas: {sample_labels.shape}\")\n",
        "        print(f\"   Rango de valores de las im√°genes: [{sample_batch.min().item():.4f}, {sample_batch.max().item():.4f}]\")\n",
        "        print(f\"   Etiquetas en el lote: {sample_labels.tolist()}\")\n",
        "    else:\n",
        "        print(\"‚ùå No se puede obtener muestra porque el dataloader no se cre√≥ correctamente\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERROR al obtener muestra: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n‚úÖ DIAGN√ìSTICO FORZADO COMPLETADO\")\n",
        "print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVLOnibDAlFL",
        "outputId": "afaf60b6-cf58-4096-a8f8-2534ebbdf8d2"
      },
      "id": "rVLOnibDAlFL",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üîç DIAGN√ìSTICO FORZADO DEL PROCESO DE ENTRENAMIENTO\n",
            "==================================================\n",
            "\n",
            "1Ô∏è‚É£ VERIFICANDO CARGA DE DATASETS:\n",
            "Intentando cargar dataset de entrenamiento desde: /content/train_images\n",
            "Clases disponibles en /content/train_images: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo']\n",
            "üîç Filtrando solo las clases: ['talgo', 'tardienta', 'ter']\n",
            "‚ùå Error al cargar el dataset: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
            "‚úÖ Dataset de entrenamiento cargado: None\n",
            "   El dataset no tiene m√©todo __len__, verificando si es un Subset\n",
            "   Clases: None\n",
            "\n",
            "2Ô∏è‚É£ VERIFICANDO DIVISI√ìN TRAIN/VAL:\n",
            "Dividiendo dataset en entrenamiento y validaci√≥n...\n",
            "‚ùå ERROR al dividir dataset: object of type 'NoneType' has no len()\n",
            "\n",
            "3Ô∏è‚É£ VERIFICANDO CREACI√ìN DE DATALOADERS:\n",
            "‚ùå No se pueden crear dataloaders porque la divisi√≥n train/val no se complet√≥ correctamente\n",
            "\n",
            "4Ô∏è‚É£ VERIFICANDO MUESTRA DE DATOS:\n",
            "‚ùå No se puede obtener muestra porque el dataloader no se cre√≥ correctamente\n",
            "\n",
            "‚úÖ DIAGN√ìSTICO FORZADO COMPLETADO\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-28-ec0a24105428>\", line 31, in <cell line: 0>\n",
            "    train_subset, val_subset = split_dataset(train_dataset, val_split=0.2)\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-18-5dcbc842463d>\", line 100, in split_dataset\n",
            "    indices = list(range(len(dataset)))\n",
            "                         ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0385af8",
      "metadata": {
        "id": "e0385af8"
      },
      "source": [
        "# # Funci√≥n para entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7ab42f09",
      "metadata": {
        "id": "7ab42f09"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    \"\"\"\n",
        "    Entrena el modelo y muestra el progreso detallado.\n",
        "\n",
        "  \"\"\"\n",
        "    print(\"\\nüöÇ INICIANDO ENTRENAMIENTO DEL MODELO - VERIFICACI√ìN INMEDIATA\")\n",
        "\n",
        "    # Verificaci√≥n inmediata de los dataloaders\n",
        "    print(f\"Train loader tiene {len(train_loader)} lotes\")\n",
        "    print(f\"Val loader tiene {len(val_loader)} lotes\")\n",
        "\n",
        "    # Verificar si hay datos en los loaders\n",
        "    if len(train_loader) == 0:\n",
        "        print(\"‚ùå ERROR CR√çTICO: El dataloader de entrenamiento est√° vac√≠o\")\n",
        "        return model\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üöÇ INICIANDO ENTRENAMIENTO DEL MODELO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Verificar que los dataloaders tengan datos\n",
        "    print(f\"\\nüìä VERIFICACI√ìN DE DATALOADERS:\")\n",
        "    print(f\"Train loader: {len(train_loader)} lotes (batch_size={BATCH_SIZE})\")\n",
        "    print(f\"Val loader: {len(val_loader)} lotes (batch_size={BATCH_SIZE})\")\n",
        "\n",
        "    if len(train_loader) == 0:\n",
        "        print(\"‚ùå ERROR: El dataloader de entrenamiento est√° vac√≠o. No hay im√°genes para entrenar.\")\n",
        "        return model\n",
        "\n",
        "    # Verificar una muestra del dataloader\n",
        "    print(\"\\nüîç VERIFICANDO MUESTRA DE DATOS:\")\n",
        "    try:\n",
        "        sample_batch, sample_labels = next(iter(train_loader))\n",
        "        print(f\"Forma del lote de im√°genes: {sample_batch.shape}\")\n",
        "        print(f\"Forma de las etiquetas: {sample_labels.shape}\")\n",
        "        print(f\"Rango de valores de las im√°genes: [{sample_batch.min().item():.4f}, {sample_batch.max().item():.4f}]\")\n",
        "        print(f\"Etiquetas en el lote: {sample_labels.tolist()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERROR al verificar muestra: {e}\")\n",
        "\n",
        "    # Resto del c√≥digo de entrenamiento con logs detallados...\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n{'='*20} √âpoca {epoch+1}/{num_epochs} {'='*20}\")\n",
        "\n",
        "        # Modo entrenamiento\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        print(f\"‚è≥ Iniciando entrenamiento de √©poca {epoch+1}...\")\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            batch_count += 1\n",
        "            if batch_idx == 0:\n",
        "                print(f\"‚úÖ Primer lote cargado correctamente\")\n",
        "\n",
        "            # Mover datos a GPU si est√° disponible\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Poner gradientes a cero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass y optimizaci√≥n\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Estad√≠sticas\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            # Mostrar progreso cada 5 lotes\n",
        "            if (batch_idx + 1) % 5 == 0 or (batch_idx + 1) == len(train_loader):\n",
        "                elapsed_time = time.time() - start_time\n",
        "                print(f\"  Lote {batch_idx+1}/{len(train_loader)} | \"\n",
        "                      f\"P√©rdida: {train_loss/(batch_idx+1):.4f} | \"\n",
        "                      f\"Precisi√≥n: {100.*train_correct/train_total:.2f}% | \"\n",
        "                      f\"Tiempo: {elapsed_time:.2f}s\")\n",
        "\n",
        "        # Calcular estad√≠sticas de entrenamiento\n",
        "        train_loss = train_loss / batch_count\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "\n",
        "        # Modo evaluaci√≥n\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        print(f\"\\n‚è≥ Iniciando evaluaci√≥n de √©poca {epoch+1}...\")\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, labels) in enumerate(val_loader):\n",
        "                batch_count += 1\n",
        "                if batch_idx == 0:\n",
        "                    print(f\"‚úÖ Primer lote de validaci√≥n cargado correctamente\")\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        # Calcular estad√≠sticas de validaci√≥n\n",
        "        val_loss = val_loss / batch_count if batch_count > 0 else 0\n",
        "        val_acc = 100. * val_correct / val_total if val_total > 0 else 0\n",
        "\n",
        "        # Mostrar resultados de la √©poca\n",
        "        print(f\"\\nüìä Resultados de √©poca {epoch+1}:\")\n",
        "        print(f\"  Entrenamiento - P√©rdida: {train_loss:.4f}, Precisi√≥n: {train_acc:.2f}%\")\n",
        "        print(f\"  Validaci√≥n - P√©rdida: {val_loss:.4f}, Precisi√≥n: {val_acc:.2f}%\")\n",
        "\n",
        "        # Guardar el mejor modelo\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            print(f\"  üíæ Guardando mejor modelo (precisi√≥n: {val_acc:.2f}%)\")\n",
        "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'models', 'best_model.pth'))\n",
        "\n",
        "    print(\"\\n‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
        "    print(f\"Mejor precisi√≥n de validaci√≥n: {best_val_acc:.2f}%\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2381cd2",
      "metadata": {
        "id": "a2381cd2"
      },
      "source": [
        "# # Funci√≥n para visualizar la matriz de confusi√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6d94874c",
      "metadata": {
        "id": "6d94874c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc55fa6-11bd-4e6c-a530-404fb995fc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funciones de evaluaci√≥n y visualizaci√≥n definidas\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para visualizar la matriz de confusi√≥n\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names, output_path=None):\n",
        "    \"\"\"\n",
        "    Genera y guarda una matriz de confusi√≥n.\n",
        "\n",
        "    La matriz de confusi√≥n muestra cu√°ntas veces el modelo predijo cada clase\n",
        "    para cada clase real, lo que ayuda a identificar errores comunes.\n",
        "\n",
        "    Args:\n",
        "        y_true: Etiquetas reales\n",
        "        y_pred: Predicciones del modelo\n",
        "        class_names: Nombres de las clases\n",
        "        output_path: Ruta para guardar la imagen\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicci√≥n')\n",
        "    plt.ylabel('Real')\n",
        "    plt.title('Matriz de Confusi√≥n')\n",
        "\n",
        "    if output_path:\n",
        "        plt.savefig(output_path, bbox_inches='tight')\n",
        "        print(f\"‚úÖ Matriz de confusi√≥n guardada en {output_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Funci√≥n para visualizar el historial de entrenamiento\n",
        "def plot_training_history(history, output_path=None):\n",
        "    \"\"\"\n",
        "    Visualiza el historial de entrenamiento.\n",
        "\n",
        "    Muestra gr√°ficos de p√©rdida y precisi√≥n durante el entrenamiento.\n",
        "\n",
        "    Args:\n",
        "        history: Diccionario con historial de entrenamiento\n",
        "        output_path: Ruta para guardar la imagen\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Gr√°fico de p√©rdida\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Entrenamiento')\n",
        "    plt.plot(history['val_loss'], label='Validaci√≥n')\n",
        "    plt.title('P√©rdida durante el entrenamiento')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('P√©rdida')\n",
        "    plt.legend()\n",
        "\n",
        "    # Gr√°fico de precisi√≥n\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Entrenamiento')\n",
        "    plt.plot(history['val_acc'], label='Validaci√≥n')\n",
        "    plt.title('Precisi√≥n durante el entrenamiento')\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('Precisi√≥n')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if output_path:\n",
        "        plt.savefig(output_path, bbox_inches='tight')\n",
        "        print(f\"‚úÖ Historial de entrenamiento guardado en {output_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Funci√≥n para extraer embeddings del dataset\n",
        "def extract_dataset_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extrae embeddings de todas las im√°genes en un dataloader.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        dataloader: Dataloader con im√°genes\n",
        "        device: Dispositivo (CPU o GPU)\n",
        "\n",
        "    Returns:\n",
        "        all_embeddings: Embeddings extra√≠dos\n",
        "        all_labels: Etiquetas correspondientes\n",
        "    \"\"\"\n",
        "    model.eval()  # Poner modelo en modo evaluaci√≥n\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # No calcular gradientes\n",
        "        for inputs, labels in tqdm(dataloader, desc=\"Extrayendo embeddings\"):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Extraer embeddings\n",
        "            embeddings = model.extract_embeddings(inputs)\n",
        "\n",
        "            # Guardar resultados\n",
        "            all_embeddings.append(embeddings.cpu().numpy())\n",
        "            all_labels.append(labels.numpy())\n",
        "\n",
        "    # Concatenar resultados\n",
        "    all_embeddings = np.vstack(all_embeddings)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    print(f\"‚úÖ Extra√≠dos {len(all_embeddings)} embeddings\")\n",
        "    return all_embeddings, all_labels\n",
        "\n",
        "# Funci√≥n para guardar embeddings\n",
        "def save_embeddings(embeddings, labels, class_names, output_path):\n",
        "    \"\"\"\n",
        "    Guarda embeddings y etiquetas en un archivo.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Embeddings extra√≠dos\n",
        "        labels: Etiquetas correspondientes\n",
        "        class_names: Nombres de las clases\n",
        "        output_path: Ruta para guardar el archivo\n",
        "    \"\"\"\n",
        "    # Convertir etiquetas num√©ricas a nombres de clase\n",
        "    label_names = [class_names[label] for label in labels]\n",
        "\n",
        "    # Crear diccionario con embeddings y etiquetas\n",
        "    data = {\n",
        "        'embeddings': embeddings.tolist(),\n",
        "        'labels': labels.tolist(),\n",
        "        'label_names': label_names,\n",
        "        'class_names': class_names\n",
        "    }\n",
        "\n",
        "    # Guardar en formato JSON\n",
        "    with open(output_path, 'w') as f:\n",
        "        json.dump(data, f)\n",
        "\n",
        "    print(f\"‚úÖ Embeddings guardados en {output_path}\")\n",
        "\n",
        "# Funci√≥n para visualizar embeddings con t-SNE\n",
        "def visualize_embeddings_tsne(embeddings, labels, class_names, output_path=None, perplexity=30, n_iter=1000):\n",
        "    \"\"\"\n",
        "    Visualiza embeddings usando t-SNE.\n",
        "\n",
        "    t-SNE es una t√©cnica para visualizar datos de alta dimensi√≥n en 2D.\n",
        "    Nos permite ver si los embeddings de diferentes clases est√°n bien separados.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Embeddings extra√≠dos\n",
        "        labels: Etiquetas correspondientes\n",
        "        class_names: Nombres de las clases\n",
        "        output_path: Ruta para guardar la imagen\n",
        "        perplexity: Par√°metro de t-SNE (30 es un buen valor por defecto)\n",
        "        n_iter: N√∫mero de iteraciones para t-SNE\n",
        "    \"\"\"\n",
        "    from sklearn.manifold import TSNE\n",
        "\n",
        "    # Reducir dimensionalidad con t-SNE\n",
        "    print(\"üîÑ Aplicando t-SNE para visualizar embeddings (esto puede tardar un poco)...\")\n",
        "    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, random_state=42)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # Crear DataFrame para visualizaci√≥n\n",
        "    df = pd.DataFrame({\n",
        "        'x': embeddings_2d[:, 0],\n",
        "        'y': embeddings_2d[:, 1],\n",
        "        'label': [class_names[label] for label in labels]\n",
        "    })\n",
        "\n",
        "    # Visualizar\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.scatterplot(data=df, x='x', y='y', hue='label', palette='tab20', s=100, alpha=0.7)\n",
        "    plt.title('Visualizaci√≥n de Embeddings con t-SNE')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "    if output_path:\n",
        "        plt.savefig(output_path, bbox_inches='tight')\n",
        "        print(f\"‚úÖ Visualizaci√≥n t-SNE guardada en {output_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Funci√≥n para evaluar la similitud entre embeddings\n",
        "def evaluate_embedding_similarity(embeddings, labels, class_names, metric='cosine'):\n",
        "    \"\"\"\n",
        "    Eval√∫a la similitud entre embeddings de la misma clase y de clases diferentes.\n",
        "\n",
        "    Esta funci√≥n es crucial para entender si nuestros embeddings son discriminativos.\n",
        "    Idealmente, la similitud intra-clase (misma clase) deber√≠a ser alta,\n",
        "    y la similitud inter-clase (clases diferentes) deber√≠a ser baja.\n",
        "\n",
        "    Args:\n",
        "        embeddings: Embeddings extra√≠dos\n",
        "        labels: Etiquetas correspondientes\n",
        "        class_names: Nombres de las clases\n",
        "        metric: M√©trica de similitud ('cosine' o 'euclidean')\n",
        "\n",
        "    Returns:\n",
        "        stats: Estad√≠sticas de similitud\n",
        "    \"\"\"\n",
        "    # Calcular matriz de similitud\n",
        "    if metric == 'cosine':\n",
        "        similarity_matrix = cosine_similarity(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        # Convertir distancia a similitud (valores m√°s altos = m√°s similares)\n",
        "        distance_matrix = euclidean_distances(embeddings)\n",
        "        max_distance = np.max(distance_matrix)\n",
        "        similarity_matrix = 1 - (distance_matrix / max_distance)\n",
        "    else:\n",
        "        raise ValueError(f\"‚ùå M√©trica {metric} no soportada\")\n",
        "\n",
        "    # Calcular similitud intra-clase e inter-clase\n",
        "    intra_class_similarities = []  # Similitudes entre im√°genes de la misma clase\n",
        "    inter_class_similarities = []  # Similitudes entre im√°genes de clases diferentes\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        for j in range(i+1, len(labels)):\n",
        "            if labels[i] == labels[j]:\n",
        "                intra_class_similarities.append(similarity_matrix[i, j])\n",
        "            else:\n",
        "                inter_class_similarities.append(similarity_matrix[i, j])\n",
        "\n",
        "    # Convertir a arrays\n",
        "    intra_class_similarities = np.array(intra_class_similarities)\n",
        "    inter_class_similarities = np.array(inter_class_similarities)\n",
        "\n",
        "    # Calcular estad√≠sticas\n",
        "    stats = {\n",
        "        'intra_class_mean': np.mean(intra_class_similarities),\n",
        "        'intra_class_std': np.std(intra_class_similarities),\n",
        "        'intra_class_min': np.min(intra_class_similarities),\n",
        "        'intra_class_max': np.max(intra_class_similarities),\n",
        "        'inter_class_mean': np.mean(inter_class_similarities),\n",
        "        'inter_class_std': np.std(inter_class_similarities),\n",
        "        'inter_class_min': np.min(inter_class_similarities),\n",
        "        'inter_class_max': np.max(inter_class_similarities),\n",
        "    }\n",
        "\n",
        "    # Visualizar distribuciones\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(intra_class_similarities, kde=True, label='Intra-clase', alpha=0.6)\n",
        "    sns.histplot(inter_class_similarities, kde=True, label='Inter-clase', alpha=0.6)\n",
        "    plt.title(f'Distribuci√≥n de Similitud ({metric})')\n",
        "    plt.xlabel('Similitud')\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Imprimir estad√≠sticas\n",
        "    print(f\"üìä Estad√≠sticas de similitud ({metric}):\")\n",
        "    print(f\"üìà Intra-clase (misma clase): Media={stats['intra_class_mean']:.4f}, Std={stats['intra_class_std']:.4f}, Min={stats['intra_class_min']:.4f}, Max={stats['intra_class_max']:.4f}\")\n",
        "    print(f\"üìâ Inter-clase (clases diferentes): Media={stats['inter_class_mean']:.4f}, Std={stats['inter_class_std']:.4f}, Min={stats['inter_class_min']:.4f}, Max={stats['inter_class_max']:.4f}\")\n",
        "\n",
        "    # Evaluar si hay buena separaci√≥n\n",
        "    if stats['intra_class_mean'] > stats['inter_class_mean'] + stats['inter_class_std']:\n",
        "        print(\"‚úÖ ¬°Buena separaci√≥n! Los embeddings de la misma clase son significativamente m√°s similares entre s√≠ que con otras clases.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Separaci√≥n insuficiente. Considera entrenar por m√°s √©pocas o ajustar hiperpar√°metros.\")\n",
        "\n",
        "    return stats\n",
        "\n",
        "# Funci√≥n para evaluar la capacidad de rechazar im√°genes negativas\n",
        "def evaluate_negative_rejection(model, negative_loader, class_names, device, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Eval√∫a la capacidad del modelo para rechazar im√°genes que no pertenecen a ninguna clase.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        negative_loader: Dataloader con im√°genes negativas\n",
        "        class_names: Nombres de las clases\n",
        "        device: Dispositivo (CPU o GPU)\n",
        "        threshold: Umbral de confianza para considerar una predicci√≥n v√°lida\n",
        "\n",
        "    Returns:\n",
        "        rejection_rate: Tasa de rechazo (porcentaje de im√°genes correctamente rechazadas)\n",
        "        confidences: Confianzas para las im√°genes negativas\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_confidences = []\n",
        "    rejected = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in tqdm(negative_loader, desc=\"Evaluando rechazo de negativos\"):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # Obtener predicciones\n",
        "            outputs = model(inputs)\n",
        "            confidences = F.softmax(outputs, dim=1)\n",
        "\n",
        "            # Obtener m√°xima confianza para cada imagen\n",
        "            max_confidences, _ = confidences.max(1)\n",
        "\n",
        "            # Contar cu√°ntas im√°genes son rechazadas (confianza < threshold)\n",
        "            rejected += (max_confidences < threshold).sum().item()\n",
        "            total += inputs.size(0)\n",
        "\n",
        "            # Guardar confianzas\n",
        "            all_confidences.extend(max_confidences.cpu().numpy())\n",
        "\n",
        "    # Calcular tasa de rechazo\n",
        "    rejection_rate = rejected / total if total > 0 else 0\n",
        "\n",
        "    # Visualizar distribuci√≥n de confianzas\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(all_confidences, kde=True, bins=20)\n",
        "    plt.axvline(x=threshold, color='r', linestyle='--', label=f'Umbral ({threshold})')\n",
        "    plt.title('Distribuci√≥n de Confianzas para Im√°genes Negativas')\n",
        "    plt.xlabel('Confianza M√°xima')\n",
        "    plt.ylabel('Frecuencia')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(f\"üìä Tasa de rechazo: {rejection_rate:.4f} ({rejected} de {total} im√°genes rechazadas)\")\n",
        "    print(f\"üìä Confianza media: {np.mean(all_confidences):.4f}\")\n",
        "    print(f\"üìä Confianza m√°xima: {np.max(all_confidences):.4f}\")\n",
        "    print(f\"üìä Confianza m√≠nima: {np.min(all_confidences):.4f}\")\n",
        "\n",
        "    if rejection_rate > 0.9:\n",
        "        print(\"‚úÖ ¬°Excelente rechazo de negativos!\")\n",
        "    elif rejection_rate > 0.7:\n",
        "        print(\"‚úÖ Buen rechazo de negativos.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Rechazo de negativos insuficiente. Considera ajustar el umbral o mejorar el modelo.\")\n",
        "\n",
        "    return rejection_rate, all_confidences\n",
        "\n",
        "print(\"‚úÖ Funciones de evaluaci√≥n y visualizaci√≥n definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce667fa8",
      "metadata": {
        "id": "ce667fa8"
      },
      "source": [
        "# # Funci√≥n para exportar modelo a ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "05f5fb53",
      "metadata": {
        "id": "05f5fb53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72aa2a6-5fe2-464b-fd7c-1915e19ca02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funciones de exportaci√≥n definidas\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para exportar modelo a ONNX\n",
        "def export_to_onnx(model, input_shape, output_path):\n",
        "    \"\"\"\n",
        "    Exporta un modelo PyTorch a formato ONNX.\n",
        "\n",
        "    ONNX es un formato est√°ndar que permite usar el modelo en diferentes plataformas.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        input_shape: Forma de la entrada (ej. (3, 224, 224) para im√°genes RGB)\n",
        "        output_path: Ruta para guardar el modelo ONNX\n",
        "\n",
        "    Returns:\n",
        "        output_path: Ruta del modelo ONNX guardado\n",
        "    \"\"\"\n",
        "    # Crear tensor de ejemplo\n",
        "    dummy_input = torch.randn(1, *input_shape, device=device)\n",
        "\n",
        "    # Poner modelo en modo evaluaci√≥n\n",
        "    model.eval()\n",
        "\n",
        "    # Exportar modelo\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        output_path,\n",
        "        export_params=True,\n",
        "        opset_version=12,\n",
        "        do_constant_folding=True,\n",
        "        input_names=['input'],\n",
        "        output_names=['output'],\n",
        "        dynamic_axes={'input': {0: 'batch_size'},\n",
        "                      'output': {0: 'batch_size'}}\n",
        "    )\n",
        "\n",
        "    # Verificar modelo ONNX\n",
        "    onnx_model = onnx.load(output_path)\n",
        "    onnx.checker.check_model(onnx_model)\n",
        "\n",
        "    print(f\"‚úÖ Modelo exportado a ONNX: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# Funci√≥n para probar inferencia con ONNX\n",
        "def test_onnx_inference(onnx_path, test_image_path, class_names, transform=None):\n",
        "    \"\"\"\n",
        "    Prueba inferencia con un modelo ONNX.\n",
        "\n",
        "    Args:\n",
        "        onnx_path: Ruta del modelo ONNX\n",
        "        test_image_path: Ruta de la imagen de prueba\n",
        "        class_names: Nombres de las clases\n",
        "        transform: Transformaciones a aplicar a la imagen\n",
        "\n",
        "    Returns:\n",
        "        pred_class: Clase predicha\n",
        "        confidence: Confianza de la predicci√≥n\n",
        "        inference_time: Tiempo de inferencia\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "\n",
        "    # Cargar imagen\n",
        "    img = Image.open(test_image_path).convert('RGB')\n",
        "\n",
        "    # Aplicar transformaciones\n",
        "    if transform is None:\n",
        "        transform = val_transforms\n",
        "\n",
        "    img_tensor = transform(img).unsqueeze(0).numpy()\n",
        "\n",
        "    # Crear sesi√≥n ONNX\n",
        "    session = onnxruntime.InferenceSession(onnx_path)\n",
        "\n",
        "    # Obtener nombres de entradas y salidas\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output_name = session.get_outputs()[0].name\n",
        "\n",
        "    # Realizar inferencia\n",
        "    start_time = time.time()\n",
        "    outputs = session.run([output_name], {input_name: img_tensor})\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    # Obtener predicci√≥n\n",
        "    probs = outputs[0][0]\n",
        "    pred_idx = np.argmax(probs)\n",
        "    pred_class = class_names[pred_idx]\n",
        "    confidence = probs[pred_idx]\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"üîç Predicci√≥n: {pred_class} (Confianza: {confidence:.4f})\")\n",
        "    print(f\"‚è±Ô∏è Tiempo de inferencia: {inference_time*1000:.2f} ms\")\n",
        "\n",
        "    # Mostrar imagen\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicci√≥n: {pred_class} ({confidence:.4f})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    return pred_class, confidence, inference_time\n",
        "\n",
        "print(\"‚úÖ Funciones de exportaci√≥n definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20ab998",
      "metadata": {
        "id": "d20ab998"
      },
      "source": [
        "# # Funci√≥n para comparar embeddings (similar a la implementaci√≥n actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f89253e7",
      "metadata": {
        "id": "f89253e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1531ad05-fb17-4400-e63e-b8e17ec34270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Funciones de inferencia definidas\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n para comparar embeddings (similar a la implementaci√≥n actual)\n",
        "def compare_embeddings(query_embedding, reference_embeddings, reference_labels, top_k=5, metric='cosine'):\n",
        "    \"\"\"\n",
        "    Compara un embedding de consulta con embeddings de referencia.\n",
        "\n",
        "    Args:\n",
        "        query_embedding: Embedding de la imagen de consulta\n",
        "        reference_embeddings: Embeddings de referencia\n",
        "        reference_labels: Etiquetas de los embeddings de referencia\n",
        "        top_k: N√∫mero de resultados a devolver\n",
        "        metric: M√©trica de similitud ('cosine' o 'euclidean')\n",
        "\n",
        "    Returns:\n",
        "        results: Lista de resultados ordenados por similitud\n",
        "    \"\"\"\n",
        "    # Calcular similitud\n",
        "    if metric == 'cosine':\n",
        "        similarities = cosine_similarity(query_embedding.reshape(1, -1), reference_embeddings)[0]\n",
        "    elif metric == 'euclidean':\n",
        "        distances = euclidean_distances(query_embedding.reshape(1, -1), reference_embeddings)[0]\n",
        "        max_distance = np.max(distances)\n",
        "        similarities = 1 - (distances / max_distance)\n",
        "    else:\n",
        "        raise ValueError(f\"‚ùå M√©trica {metric} no soportada\")\n",
        "\n",
        "    # Obtener top-k\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    top_similarities = similarities[top_indices]\n",
        "    top_labels = [reference_labels[i] for i in top_indices]\n",
        "\n",
        "    # Crear resultados\n",
        "    results = []\n",
        "    for i in range(len(top_indices)):\n",
        "        results.append({\n",
        "            'label': top_labels[i],\n",
        "            'similarity': float(top_similarities[i]),\n",
        "            'index': int(top_indices[i])\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Funci√≥n para extraer embedding de una imagen\n",
        "def extract_image_embedding(model, image_path, transform=None, device=None):\n",
        "    \"\"\"\n",
        "    Extrae el embedding de una imagen.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        image_path: Ruta de la imagen\n",
        "        transform: Transformaciones a aplicar\n",
        "        device: Dispositivo (CPU o GPU)\n",
        "\n",
        "    Returns:\n",
        "        embedding: Embedding de la imagen\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if transform is None:\n",
        "        transform = val_transforms\n",
        "\n",
        "    # Cargar y transformar imagen\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    # Extraer embedding\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        embedding = model.extract_embeddings(img_tensor)\n",
        "\n",
        "    return embedding.cpu().numpy()[0]\n",
        "\n",
        "# Funci√≥n para clasificar una imagen usando embeddings\n",
        "def classify_image_with_embeddings(model, image_path, reference_embeddings, reference_labels, class_names,\n",
        "                                  transform=None, device=None, top_k=5, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Clasifica una imagen usando embeddings.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo entrenado\n",
        "        image_path: Ruta de la imagen\n",
        "        reference_embeddings: Embeddings de referencia\n",
        "        reference_labels: Etiquetas de los embeddings de referencia\n",
        "        class_names: Nombres de las clases\n",
        "        transform: Transformaciones a aplicar\n",
        "        device: Dispositivo (CPU o GPU)\n",
        "        top_k: N√∫mero de resultados a devolver\n",
        "        threshold: Umbral de similitud para considerar una predicci√≥n v√°lida\n",
        "\n",
        "    Returns:\n",
        "        results: Resultados de la clasificaci√≥n\n",
        "        is_rejected: Si la imagen fue rechazada (similitud < threshold)\n",
        "    \"\"\"\n",
        "    # Extraer embedding de la imagen\n",
        "    query_embedding = extract_image_embedding(model, image_path, transform, device)\n",
        "\n",
        "    # Comparar con embeddings de referencia\n",
        "    results = compare_embeddings(query_embedding, reference_embeddings, reference_labels, top_k)\n",
        "\n",
        "    # Verificar si la similitud est√° por debajo del umbral\n",
        "    is_rejected = results[0]['similarity'] < threshold\n",
        "\n",
        "    # Mostrar imagen\n",
        "    from PIL import Image\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(img)\n",
        "\n",
        "    if is_rejected:\n",
        "        plt.title(f\"‚ùå RECHAZADA: No es ninguna clase conocida\\nMejor coincidencia: {results[0]['label']} ({results[0]['similarity']:.4f})\")\n",
        "    else:\n",
        "        plt.title(f\"‚úÖ ACEPTADA: {results[0]['label']} ({results[0]['similarity']:.4f})\")\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"üîç Resultados para {image_path}:\")\n",
        "    for i, result in enumerate(results):\n",
        "        status = \"‚úÖ\" if i == 0 and not is_rejected else \"‚ùå\" if i == 0 else \"  \"\n",
        "        print(f\"{status} {i+1}. {result['label']} (Similitud: {result['similarity']:.4f})\")\n",
        "\n",
        "    if is_rejected:\n",
        "        print(f\"‚ùå La imagen fue RECHAZADA porque la similitud ({results[0]['similarity']:.4f}) est√° por debajo del umbral ({threshold})\")\n",
        "    else:\n",
        "        print(f\"‚úÖ La imagen fue ACEPTADA como {results[0]['label']}\")\n",
        "\n",
        "    return results, is_rejected\n",
        "\n",
        "print(\"‚úÖ Funciones de inferencia definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aca1fff",
      "metadata": {
        "id": "0aca1fff"
      },
      "source": [
        "# def inference_code_example():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b4f24c04",
      "metadata": {
        "id": "b4f24c04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9260987-b417-4d22-d789-13e6af959234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ C√≥digo de ejemplo para inferencia definido\n"
          ]
        }
      ],
      "source": [
        "def inference_code_example():\n",
        "    \"\"\"\n",
        "    Ejemplo de c√≥digo para inferencia en CPU.\n",
        "\n",
        "    Este c√≥digo puede ser usado en un entorno de producci√≥n\n",
        "    para clasificar nuevas im√°genes usando el modelo entrenado.\n",
        "    \"\"\"\n",
        "    code = \"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import onnxruntime\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "MODEL_PATH = \"models/efficientnet_model.onnx\"  # Ruta al modelo ONNX\n",
        "EMBEDDINGS_PATH = \"embeddings/dataset_embeddings.json\"  # Ruta a los embeddings de referencia\n",
        "IMG_SIZE = 224\n",
        "THRESHOLD = 0.6  # Umbral para rechazar im√°genes desconocidas\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def load_reference_embeddings(embeddings_path):\n",
        "    with open(embeddings_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    embeddings = np.array(data['embeddings'])\n",
        "    labels = data['label_names']\n",
        "    class_names = data['class_names']\n",
        "\n",
        "    print(f\"Cargados {len(embeddings)} embeddings de referencia para {len(set(labels))} clases\")\n",
        "    return embeddings, labels, class_names\n",
        "\n",
        "def extract_embedding_onnx(image_path, model_path, transform):\n",
        "    # Cargar y transformar imagen\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).numpy()\n",
        "\n",
        "    # Crear sesi√≥n ONNX\n",
        "    session = onnxruntime.InferenceSession(model_path)\n",
        "\n",
        "    # Obtener nombres de entradas y salidas\n",
        "    input_name = session.get_inputs()[0].name\n",
        "    output_name = session.get_outputs()[0].name\n",
        "\n",
        "    # Realizar inferencia\n",
        "    outputs = session.run([output_name], {input_name: img_tensor})\n",
        "    embedding = outputs[0]\n",
        "\n",
        "    # Normalizar embedding (L2)\n",
        "    embedding_norm = embedding / np.linalg.norm(embedding, axis=1, keepdims=True)\n",
        "\n",
        "    return embedding_norm[0]\n",
        "\n",
        "def compare_embeddings(query_embedding, reference_embeddings, reference_labels, top_k=5):\n",
        "    # Calcular similitud coseno\n",
        "    similarities = cosine_similarity(query_embedding.reshape(1, -1), reference_embeddings)[0]\n",
        "\n",
        "    # Obtener top-k\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    top_similarities = similarities[top_indices]\n",
        "    top_labels = [reference_labels[i] for i in top_indices]\n",
        "\n",
        "    # Crear resultados\n",
        "    results = []\n",
        "    for i in range(len(top_indices)):\n",
        "        results.append({\n",
        "            'label': top_labels[i],\n",
        "            'similarity': float(top_similarities[i]),\n",
        "            'index': int(top_indices[i])\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Funci√≥n principal para clasificar una imagen\n",
        "def classify_image(image_path, model_path, embeddings_path, top_k=5, threshold=THRESHOLD):\n",
        "    # Cargar embeddings de referencia\n",
        "    reference_embeddings, reference_labels, class_names = load_reference_embeddings(embeddings_path)\n",
        "\n",
        "    # Extraer embedding de la imagen\n",
        "    query_embedding = extract_embedding_onnx(image_path, model_path, transform)\n",
        "\n",
        "    # Comparar con referencias\n",
        "    results = compare_embeddings(query_embedding, reference_embeddings, reference_labels, top_k)\n",
        "\n",
        "    # Verificar si la similitud est√° por debajo del umbral\n",
        "    is_rejected = results[0]['similarity'] < threshold\n",
        "\n",
        "    # Mostrar resultados\n",
        "    print(f\"Resultados para {image_path}:\")\n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"{i+1}. {result['label']} (Similitud: {result['similarity']:.4f})\")\n",
        "\n",
        "    if is_rejected:\n",
        "        print(f\"La imagen fue RECHAZADA porque la similitud ({results[0]['similarity']:.4f}) est√° por debajo del umbral ({threshold})\")\n",
        "    else:\n",
        "        print(f\"La imagen fue ACEPTADA como {results[0]['label']}\")\n",
        "\n",
        "    return results, is_rejected\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"ruta/a/imagen_de_prueba.jpg\"\n",
        "    results, is_rejected = classify_image(image_path, MODEL_PATH, EMBEDDINGS_PATH, top_k=5)\n",
        "\"\"\"\n",
        "    return code\n",
        "\n",
        "print(\"‚úÖ C√≥digo de ejemplo para inferencia definido\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b74eb2",
      "metadata": {
        "id": "17b74eb2"
      },
      "source": [
        "# # Funci√≥n principal para entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4f19b7ea",
      "metadata": {
        "id": "4f19b7ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc64b5d8-5417-4caa-f666-b340704b3b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando entrenamiento del modelo para clasificaci√≥n de trenes\n",
            "\n",
            "üìÇ PASO 1: Cargando dataset\n",
            "Clases disponibles en /content/train_images: ['.ipynb_checkpoints', 'tardienta', 'ter', 'talgo']\n",
            "üîç Filtrando solo las clases: ['talgo', 'ter', 'tardienta']\n",
            "‚ùå Error al cargar el dataset: Found no valid file for the classes .ipynb_checkpoints. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp\n",
            "‚ùå Error al cargar el dataset. Abortando.\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n principal para entrenar el modelo\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Funci√≥n principal que ejecuta todo el flujo de entrenamiento y evaluaci√≥n.\n",
        "    \"\"\"\n",
        "    print(\"üöÄ Iniciando entrenamiento del modelo para clasificaci√≥n de trenes\")\n",
        "\n",
        "    # Paso 1: Cargar dataset\n",
        "    print(\"\\nüìÇ PASO 1: Cargando dataset\")\n",
        "    full_dataset, class_names = load_dataset(\n",
        "        config.DATA_DIR,\n",
        "        transform=train_transforms,\n",
        "        selected_classes=config.SELECTED_CLASSES\n",
        "    )\n",
        "\n",
        "    if full_dataset is None:\n",
        "        print(\"‚ùå Error al cargar el dataset. Abortando.\")\n",
        "        return\n",
        "\n",
        "    # Paso 2: Dividir dataset\n",
        "    print(\"\\n‚úÇÔ∏è PASO 2: Dividiendo dataset en entrenamiento y validaci√≥n\")\n",
        "    train_dataset, val_dataset = split_dataset(full_dataset, val_split=config.VALIDATION_SPLIT)\n",
        "\n",
        "    # Paso 3: Crear dataloaders\n",
        "    print(\"\\nüîÑ PASO 3: Creando dataloaders\")\n",
        "    train_loader, val_loader = create_dataloaders(train_dataset, val_dataset, batch_size=config.BATCH_SIZE)\n",
        "\n",
        "    # Paso 4: Crear modelo\n",
        "    print(\"\\nüß† PASO 4: Creando modelo\")\n",
        "    num_classes = len(class_names)\n",
        "    model = EmbeddingModel(config.MODEL_NAME, num_classes, embedding_size=config.EMBEDDING_SIZE)\n",
        "    model = model.to(device)\n",
        "    print(f\"‚úÖ Modelo creado: {config.MODEL_NAME} con {num_classes} clases\")\n",
        "\n",
        "    # Paso 5: Definir criterio y optimizador\n",
        "    print(\"\\n‚öôÔ∏è PASO 5: Configurando criterio y optimizador\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    # Paso 6: Entrenar modelo\n",
        "    print(\"\\nüèãÔ∏è PASO 6: Entrenando modelo\")\n",
        "    model, history = train_model(\n",
        "        model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
        "        num_epochs=config.NUM_EPOCHS,\n",
        "        device=device,\n",
        "        early_stopping_patience=config.EARLY_STOPPING_PATIENCE,\n",
        "        mixed_precision=config.USE_MIXED_PRECISION\n",
        "    )\n",
        "\n",
        "    # Paso 7: Guardar modelo\n",
        "    print(\"\\nüíæ PASO 7: Guardando modelo\")\n",
        "    model_path = os.path.join(config.OUTPUT_DIR, \"models\", f\"{config.MODEL_NAME}_model.pth\")\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'class_names': class_names,\n",
        "        'config': vars(config)\n",
        "    }, model_path)\n",
        "    print(f\"‚úÖ Modelo guardado en {model_path}\")\n",
        "\n",
        "    # Paso 8: Visualizar historial de entrenamiento\n",
        "    print(\"\\nüìä PASO 8: Visualizando historial de entrenamiento\")\n",
        "    history_path = os.path.join(config.OUTPUT_DIR, \"visualizations\", \"training_history.png\")\n",
        "    plot_training_history(history, output_path=history_path)\n",
        "\n",
        "    # Paso 9: Evaluar modelo en conjunto de validaci√≥n\n",
        "    print(\"\\nüîç PASO 9: Evaluando modelo en conjunto de validaci√≥n\")\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(val_loader, desc=\"Evaluando\"):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = outputs.max(1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    # Generar matriz de confusi√≥n\n",
        "    cm_path = os.path.join(config.OUTPUT_DIR, \"visualizations\", \"confusion_matrix.png\")\n",
        "    plot_confusion_matrix(val_targets, val_preds, class_names, output_path=cm_path)\n",
        "\n",
        "    # Generar informe de clasificaci√≥n\n",
        "    report = classification_report(val_targets, val_preds, target_names=class_names)\n",
        "    print(\"üìã Informe de clasificaci√≥n:\")\n",
        "    print(report)\n",
        "\n",
        "    # Guardar informe\n",
        "    report_path = os.path.join(config.OUTPUT_DIR, \"classification_report.txt\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write(report)\n",
        "\n",
        "    # Paso 10: Extraer embeddings\n",
        "    print(\"\\nüß© PASO 10: Extrayendo embeddings\")\n",
        "\n",
        "    # Crear dataloader con transformaciones de validaci√≥n para todo el dataset\n",
        "    full_dataset_val, _ = load_dataset(\n",
        "        config.DATA_DIR,\n",
        "        transform=val_transforms,\n",
        "        selected_classes=config.SELECTED_CLASSES\n",
        "    )\n",
        "    full_loader = DataLoader(full_dataset_val, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Extraer embeddings\n",
        "    embeddings, labels = extract_dataset_embeddings(model, full_loader, device)\n",
        "\n",
        "    # Guardar embeddings\n",
        "    embeddings_path = os.path.join(config.OUTPUT_DIR, \"embeddings\", \"dataset_embeddings.json\")\n",
        "    save_embeddings(embeddings, labels, class_names, embeddings_path)\n",
        "\n",
        "    # Paso 11: Visualizar embeddings con t-SNE\n",
        "    print(\"\\nüé® PASO 11: Visualizando embeddings con t-SNE\")\n",
        "    tsne_path = os.path.join(config.OUTPUT_DIR, \"visualizations\", \"embeddings_tsne.png\")\n",
        "    visualize_embeddings_tsne(embeddings, labels, class_names, output_path=tsne_path)\n",
        "\n",
        "    # Paso 12: Evaluar similitud de embeddings\n",
        "    print(\"\\nüìè PASO 12: Evaluando similitud de embeddings\")\n",
        "    similarity_stats = evaluate_embedding_similarity(embeddings, labels, class_names, metric='cosine')\n",
        "\n",
        "    # Paso 13: Evaluar rechazo de negativos (si hay im√°genes negativas)\n",
        "    print(\"\\nüö´ PASO 13: Evaluando rechazo de im√°genes negativas\")\n",
        "    try:\n",
        "        # Intentar cargar im√°genes negativas (otros tipos de trenes)\n",
        "        negative_dir = os.path.join(config.TEST_DIR, \"otros\")\n",
        "        if os.path.exists(negative_dir):\n",
        "            negative_dataset = datasets.ImageFolder(root=negative_dir, transform=val_transforms)\n",
        "            negative_loader = DataLoader(negative_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "            # Evaluar rechazo\n",
        "            rejection_rate, confidences = evaluate_negative_rejection(model, negative_loader, class_names, device)\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No se encontr√≥ directorio de im√°genes negativas. Saltando evaluaci√≥n de rechazo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error al evaluar rechazo de negativos: {e}\")\n",
        "\n",
        "    # Paso 14: Exportar modelo a ONNX\n",
        "    print(\"\\nüì¶ PASO 14: Exportando modelo a ONNX\")\n",
        "    if config.EXPORT_FORMAT == \"onnx\":\n",
        "        onnx_path = os.path.join(config.OUTPUT_DIR, \"models\", f\"{config.MODEL_NAME}_model.onnx\")\n",
        "        export_to_onnx(model, (3, config.IMG_SIZE, config.IMG_SIZE), onnx_path)\n",
        "\n",
        "    # Paso 15: Mostrar c√≥digo de ejemplo para inferencia\n",
        "    print(\"\\nüìù PASO 15: C√≥digo de ejemplo para inferencia en CPU\")\n",
        "    inference_code = inference_code_example()\n",
        "    inference_code_path = os.path.join(config.OUTPUT_DIR, \"inference_example.py\")\n",
        "    with open(inference_code_path, 'w') as f:\n",
        "        f.write(inference_code)\n",
        "    print(f\"‚úÖ C√≥digo de ejemplo guardado en {inference_code_path}\")\n",
        "\n",
        "    print(\"\\nüéâ Entrenamiento y evaluaci√≥n completados con √©xito!\")\n",
        "    print(f\"üìÇ Todos los resultados est√°n guardados en: {config.OUTPUT_DIR}\")\n",
        "    print(\"üîç Puedes usar el modelo para clasificar nuevas im√°genes con el c√≥digo de ejemplo proporcionado.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "772f238b",
      "metadata": {
        "id": "772f238b"
      },
      "source": [
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fce3e4f",
      "metadata": {
        "id": "8fce3e4f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "INSTRUCCIONES PARA USAR ESTE NOTEBOOK:\n",
        "\n",
        "1. PREPARACI√ìN DE DATOS:\n",
        "   - Sube tus im√°genes a Google Drive en carpetas organizadas por clase\n",
        "   - Estructura recomendada:\n",
        "     /content/train_images/\n",
        "       ‚îú‚îÄ‚îÄ talgo/       # Im√°genes de TALGO\n",
        "       ‚îú‚îÄ‚îÄ ter/         # Im√°genes de TER\n",
        "       ‚îî‚îÄ‚îÄ tardienta/   # Im√°genes de TARDIENTA\n",
        "\n",
        "     /content/test_images/\n",
        "       ‚îú‚îÄ‚îÄ talgo/       # Im√°genes de prueba de TALGO\n",
        "       ‚îú‚îÄ‚îÄ ter/         # Im√°genes de prueba de TER\n",
        "       ‚îú‚îÄ‚îÄ tardienta/   # Im√°genes de prueba de TARDIENTA\n",
        "       ‚îî‚îÄ‚îÄ otros/       # Im√°genes de otros tipos de trenes (negativas)\n",
        "\n",
        "2. CONFIGURACI√ìN:\n",
        "   - Ajusta los par√°metros en la clase Config seg√∫n tus necesidades\n",
        "   - Especialmente, verifica las rutas DATA_DIR y TEST_DIR\n",
        "\n",
        "3. EJECUCI√ìN:\n",
        "   - Ejecuta todas las celdas en orden\n",
        "   - El entrenamiento puede tardar varios minutos dependiendo de la cantidad de im√°genes\n",
        "\n",
        "4. RESULTADOS:\n",
        "   - Todos los resultados se guardar√°n en OUTPUT_DIR\n",
        "   - Incluye modelo entrenado, embeddings, visualizaciones y c√≥digo de ejemplo\n",
        "\n",
        "5. USO DEL MODELO:\n",
        "   - Usa el c√≥digo de ejemplo proporcionado para clasificar nuevas im√°genes\n",
        "   - Puedes ajustar el umbral de similitud para controlar el rechazo de im√°genes desconocidas\n",
        "\n",
        "6. EXPANSI√ìN:\n",
        "   - Cuando est√©s satisfecho con los resultados, puedes expandir a m√°s clases\n",
        "   - Simplemente a√±ade m√°s carpetas con im√°genes y actualiza SELECTED_CLASSES en Config\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}